[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Tidyverse",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh."
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html",
    "title": "Machine Learninng Fundamentals",
    "section": "",
    "text": "title: “Session 6 - Challenge - Company Segmentation” date: “7/24/2020” output: html_document: toc: TRUE theme: flatly highlight: tango code_folding: hide df_print: paged —"
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-1---convert-stock-prices-to-a-standardized-format-daily-returns",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-1---convert-stock-prices-to-a-standardized-format-daily-returns",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.1 Step 1 - Convert stock prices to a standardized format (daily returns)",
    "text": "5.1 Step 1 - Convert stock prices to a standardized format (daily returns)\nWhat you first need to do is get the data in a format that can be converted to a “user-item” style matrix. The challenge here is to connect the dots between what we have and what we need to do to format it properly.\nWe know that in order to compare the data, it needs to be standardized or normalized. Why? Because we cannot compare values (stock prices) that are of completely different magnitudes. In order to standardize, we will convert from adjusted stock price (dollar value) to daily returns (percent change from previous day). Here is the formula.\n\\[\nreturn_{daily} = \\frac{price_{i}-price_{i-1}}{price_{i-1}}\n\\]\nFirst, what do we have? We have stock prices for every stock in the SP 500 Index, which is the daily stock prices for over 500 stocks. The data set is over 1.2M observations.\n\nsp_500_prices_tbl %>% glimpse()\n\n#> Rows: 1,225,765\n#> Columns: 8\n#> $ symbol   <chr> \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT\", \"MSFT…\n#> $ date     <date> 2009-01-02, 2009-01-05, 2009-01-06, 2009-01-07, 2009-01-08, …\n#> $ open     <dbl> 19.53, 20.20, 20.75, 20.19, 19.63, 20.17, 19.71, 19.52, 19.53…\n#> $ high     <dbl> 20.40, 20.67, 21.00, 20.29, 20.19, 20.30, 19.79, 19.99, 19.68…\n#> $ low      <dbl> 19.37, 20.06, 20.61, 19.48, 19.55, 19.41, 19.30, 19.52, 19.01…\n#> $ close    <dbl> 20.33, 20.52, 20.76, 19.51, 20.12, 19.52, 19.47, 19.82, 19.09…\n#> $ volume   <dbl> 50084000, 61475200, 58083400, 72709900, 70255400, 49815300, 5…\n#> $ adjusted <dbl> 15.86624, 16.01451, 16.20183, 15.22628, 15.70234, 15.23408, 1…\n\n\nYour first task is to convert to a tibble named sp_500_daily_returns_tbl by performing the following operations:\n\nSelect the symbol, date and adjusted columns\nFilter to dates beginning in the year 2018 and beyond.\nCompute a Lag of 1 day on the adjusted stock price. Be sure to group by symbol first, otherwise we will have lags computed using values from the previous stock in the data frame.\nRemove a NA values from the lagging operation\nCompute the difference between adjusted and the lag\nCompute the percentage difference by dividing the difference by that lag. Name this column pct_return.\nReturn only the symbol, date, and pct_return columns\nSave as a variable named sp_500_daily_returns_tbl\n\n\n\n# Apply your data transformation skills!\n\n#- Select the `symbol`, `date` and `adjusted` columns\n\nsp_500_daily_returns_tbl <- sp_500_prices_tbl %>% \n  select(symbol, date, adjusted)\n\n#- Filter to dates beginning in the year 2018 and beyond. \n\nsp_500_daily_returns_tbl <- subset(sp_500_daily_returns_tbl, format(date, \"%Y\") >= \"2018\")\n\n# - Compute a Lag of 1 day on the adjusted stock price. Be sure to group by symbol first, otherwise we will have lags computed using values from the previous stock in the data frame. \n# - Remove a `NA` values from the lagging operation\n\nsp_500_daily_returns_tbl <- sp_500_daily_returns_tbl %>%\n  group_by(symbol) %>%\n  mutate(lag_price = lag(adjusted)) %>%\n  na.omit(sp_500_daily_returns_tbl)\n\n\n# - Compute the difference between adjusted and the lag\n\nsp_500_daily_returns_tbl <- sp_500_daily_returns_tbl %>%\n  mutate(diff_price = adjusted - lag_price)\n\n# - Compute the percentage difference by dividing the difference by that lag. Name this column `pct_return`.\n\nsp_500_daily_returns_tbl <- sp_500_daily_returns_tbl %>%\n  mutate(pct_return = diff_price/ lag_price ) %>%\n  select(symbol, date, pct_return)\n\n\n# Output: sp_500_daily_returns_tbl\n\nsp_500_daily_returns_tbl"
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-2---convert-to-user-item-format",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-2---convert-to-user-item-format",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.2 Step 2 - Convert to User-Item Format",
    "text": "5.2 Step 2 - Convert to User-Item Format\nThe next step is to convert to a user-item format with the symbol in the first column and every other column the value of the daily returns (pct_return) for every stock at each date.\nWe’re going to import the correct results first (just in case you were not able to complete the last step).\n\nsp_500_daily_returns_tbl <- read_rds(\"sp_500_daily_returns_tbl.rds\")\nsp_500_daily_returns_tbl\n\n\n\n  \n\n\n\nNow that we have the daily returns (percentage change from one day to the next), we can convert to a user-item format. The user in this case is the symbol (company), and the item in this case is the pct_return at each date.\n\nSpread the date column to get the values as percentage returns. Make sure to fill an NA values with zeros.\nSave the result as stock_date_matrix_tbl\n\n\n\n# Convert to User-Item Format\n\n# - Spread the `date` column to get the values as percentage returns. Make sure to fill an `NA` values with zeros. \n\nstock_date_matrix_tbl <- sp_500_daily_returns_tbl %>%\n  spread(date,pct_return, fill = 0)\nstock_date_matrix_tbl\n\n\n\n  \n\n\n# Output: stock_date_matrix_tbl"
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-3---perform-k-means-clustering",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-3---perform-k-means-clustering",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.3 Step 3 - Perform K-Means Clustering",
    "text": "5.3 Step 3 - Perform K-Means Clustering\nNext, we’ll perform K-Means clustering.\nWe’re going to import the correct results first (just in case you were not able to complete the last step).\n\nstock_date_matrix_tbl <- read_rds(\"stock_date_matrix_tbl.rds\")\nstock_date_matrix_tbl\n\n\n\n  \n\n\n\nBeginning with the stock_date_matrix_tbl, perform the following operations:\n\nDrop the non-numeric column, symbol\n\nPerform kmeans() with centers = 4 and nstart = 20\n\nSave the result as kmeans_obj\n\n\n\n# Create kmeans_obj for 4 centers\n\n# - Drop the non-numeric column, `symbol`\n\nstock_date_matrix_numeric_tbl <- stock_date_matrix_tbl %>%\n  select(-symbol)\n\nkmeans_obj <- stock_date_matrix_numeric_tbl %>%\n    kmeans(centers = 4, nstart = 20)\n\nkmeans_obj$cluster\n\n#>   [1] 2 1 2 1 2 2 1 2 2 1 1 2 2 2 1 3 3 3 2 2 2 3 2 2 1 2 1 2 2 2 1 1 1 2 2 2 2\n#>  [38] 3 1 1 1 2 2 2 4 4 2 2 2 3 2 3 1 3 1 2 3 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2\n#>  [75] 2 2 2 3 2 3 2 2 2 2 2 2 3 1 2 2 2 2 2 3 2 2 2 2 3 3 2 2 2 2 2 3 2 3 2 2 2\n#> [112] 4 2 2 3 2 2 1 1 2 2 2 2 2 2 4 4 3 2 2 2 2 2 2 2 2 2 2 2 3 2 2 3 2 3 3 2 4\n#> [149] 2 2 1 2 2 3 2 3 2 2 2 4 3 3 3 3 2 2 3 3 1 3 2 2 3 2 4 2 1 2 4 2 3 1 2 2 2\n#> [186] 2 2 4 2 2 2 2 2 2 3 4 1 2 2 2 2 3 2 2 1 1 2 1 2 2 2 2 2 4 2 2 2 2 3 2 4 4\n#> [223] 2 2 2 2 2 2 4 1 2 2 3 2 2 2 3 2 2 2 1 2 1 1 2 1 1 2 2 1 2 2 3 1 2 2 2 2 2\n#> [260] 2 2 2 2 2 2 2 3 2 1 3 3 1 3 4 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 1 2 3 2\n#> [297] 2 1 3 3 2 2 1 3 1 2 2 3 2 2 1 2 3 2 2 2 2 3 2 4 2 4 2 1 1 2 2 2 1 1 2 4 2\n#> [334] 2 3 2 1 3 2 1 2 2 4 3 2 1 2 2 1 2 2 2 3 4 2 2 2 4 2 2 2 3 3 2 2 3 2 2 2 2\n#> [371] 2 3 3 2 2 3 2 3 2 2 3 4 2 2 4 1 2 1 2 2 3 2 2 1 2 2 2 2 2 2 2 2 2 2 3 2 2\n#> [408] 2 2 2 3 4 3 2 1 3 3 2 3 2 2 1 2 2 1 2 2 1 3 2 3 2 2 2 2 2 2 2 2 2 1 2 2 2\n#> [445] 3 1 1 1 1 2 1 1 2 3 2 2 2 2 2 2 1 2 2 1 2 2 2 4 2 3 2 1 1 3 3 2 2 2 1 3 3\n#> [482] 2 2 2 3 4 2 2 2 3 1 4 3 1 4 2 2 2 2 2 2 2\n\n\nUse glance() to get the tot.withinss.\n\n# Apply glance() to get the tot.withinss\n\nbroom::glance(kmeans_obj)"
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-4---find-the-optimal-value-of-k",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-4---find-the-optimal-value-of-k",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.4 Step 4 - Find the optimal value of K",
    "text": "5.4 Step 4 - Find the optimal value of K\nNow that we are familiar with the process for calculating kmeans(), let’s use purrr to iterate over many values of “k” using the centers argument.\nWe’ll use this custom function called kmeans_mapper():\n\nkmeans_mapper <- function(center = 3) {\n    stock_date_matrix_tbl %>%\n        select(-symbol) %>%\n        kmeans(centers = center, nstart = 20)\n}\n\nApply the kmeans_mapper() and glance() functions iteratively using purrr.\n\nCreate a tibble containing column called centers that go from 1 to 30\nAdd a column named k_means with the kmeans_mapper() output. Use mutate() to add the column and map() to map centers to the kmeans_mapper() function.\nAdd a column named glance with the glance() output. Use mutate() and map() again to iterate over the column of k_means.\nSave the output as k_means_mapped_tbl\n\n\n\n# Use purrr to map\n\nkmeans_mapped_tbl <- tibble(centers = 1:15) %>%\n    mutate(k_means = centers %>% map(kmeans_mapper)) %>%\n    mutate(glance  = k_means %>% map(glance))\n\n# Output: k_means_mapped_tbl \n\nNext, let’s visualize the “tot.withinss” from the glance output as a Scree Plot.\n\nBegin with the k_means_mapped_tbl\n\nUnnest the glance column\nPlot the centers column (x-axis) versus the tot.withinss column (y-axis) using geom_point() and geom_line()\n\nAdd a title “Scree Plot” and feel free to style it with your favorite theme\n\n\n# Visualize Scree Plot\n\n# - Begin with the `k_means_mapped_tbl`\n# - Unnest the `glance` column\n\nkmeans_mapped_tbl %>%\n    unnest(glance) %>%\n    select(centers, tot.withinss) %>%\n  # Visualization\n    ggplot(aes(centers, tot.withinss)) +\n    geom_point(color = \"#2DC6D6\", size = 4) +\n    geom_line(color = \"#2DC6D6\", size = 1) +\n    # Add labels (which are repelled a little)\n    ggrepel::geom_label_repel(aes(label = centers), color = \"#2DC6D6\") + \n    \n    # Formatting\n    labs(title = \"Skree Plot\",\n    caption = \"We can see that the Scree Plot becomes linear (constant rate of change) between 5 and 10 centers for K.\")\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nWe can see that the Scree Plot becomes linear (constant rate of change) between 5 and 10 centers for K."
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-5---apply-umap",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-5---apply-umap",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.5 Step 5 - Apply UMAP",
    "text": "5.5 Step 5 - Apply UMAP\nNext, let’s plot the UMAP 2D visualization to help us investigate cluster assignments.\nWe’re going to import the correct results first (just in case you were not able to complete the last step).\n\nk_means_mapped_tbl <- read_rds(\"k_means_mapped_tbl.rds\")\n\nFirst, let’s apply the umap() function to the stock_date_matrix_tbl, which contains our user-item matrix in tibble format.\n\nStart with stock_date_matrix_tbl\n\nDe-select the symbol column\nUse the umap() function storing the output as umap_results\n\n\n\n# Apply UMAP\n\numap_results <- stock_date_matrix_tbl %>%\n    select(-symbol) %>%\n    umap()\n\n# Store results as: umap_results \n\nNext, we want to combine the layout from the umap_results with the symbol column from the stock_date_matrix_tbl.\n\nStart with umap_results$layout\n\nConvert from a matrix data type to a tibble with as_tibble()\n\nBind the columns of the umap tibble with the symbol column from the stock_date_matrix_tbl.\nSave the results as umap_results_tbl.\n\n\n# Convert umap results to tibble with symbols\n\numap_results_tbl <- umap_results$layout %>%\n    as_tibble(.name_repair = \"unique\") %>% # argument is required to set names in the next step\n    set_names(c(\"x\", \"y\")) %>%\n    bind_cols(\n        stock_date_matrix_tbl %>% select(symbol)\n    )\n\n#> New names:\n#> • `` -> `...1`\n#> • `` -> `...2`\n\n# Output: umap_results_tbl\n\nFinally, let’s make a quick visualization of the umap_results_tbl.\n\nPipe the umap_results_tbl into ggplot() mapping the columns to x-axis and y-axis\nAdd a geom_point() geometry with an alpha = 0.5\n\nApply theme_tq() and add a title “UMAP Projection”\n\n\n# Visualize UMAP results\n\numap_results_tbl %>%\n    ggplot(aes(x, y)) +\n    geom_point(alpha = 0.5) +\n    theme_tq() +\n    labs(title = \"UMAP Projection\")\n\n\n\n\n\n\numap_results_tbl\n\n\n\n  \n\n\n\nWe can now see that we have some clusters. However, we still need to combine the K-Means clusters and the UMAP 2D representation."
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-6---combine-k-means-and-umap",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#step-6---combine-k-means-and-umap",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.6 Step 6 - Combine K-Means and UMAP",
    "text": "5.6 Step 6 - Combine K-Means and UMAP\nNext, we combine the K-Means clusters and the UMAP 2D representation\nWe’re going to import the correct results first (just in case you were not able to complete the last step).\n\nk_means_mapped_tbl <- read_rds(\"k_means_mapped_tbl.rds\")\numap_results_tbl   <- read_rds(\"umap_results_tbl.rds\")\n\nFirst, pull out the K-Means for 10 Centers. Use this since beyond this value the Scree Plot flattens. Have a look at the business case to recall how that works.\n\n# Get the k_means_obj from the 10th center\n\nk_means_obj <- kmeans_mapped_tbl %>%\n    pull(k_means) %>%\n    pluck(10)\n\n# Store as k_means_obj\n\nNext, we’ll combine the clusters from the k_means_obj with the umap_results_tbl.\n\nBegin with the k_means_obj\n\nAugment the k_means_obj with the stock_date_matrix_tbl to get the clusters added to the end of the tibble\nSelect just the symbol and .cluster columns\nLeft join the result with the umap_results_tbl by the symbol column\nLeft join the result with the result of sp_500_index_tbl %>% select(symbol, company, sector) by the symbol column.\nStore the output as umap_kmeans_results_tbl\n\n\n\n# Use your dplyr & broom skills to combine the k_means_obj with the umap_results_tbl\n\n# Convert it to a tibble with broom\nkmeans_10_clusters_tbl <- k_means_obj %>% \n    augment(stock_date_matrix_tbl) %>%\n    # Select the data we need\n    select(symbol, .cluster)\n\n# Bind data together\njoined_data <- umap_results_tbl %>%\n    left_join(kmeans_10_clusters_tbl, by = \"symbol\")\n\numap_kmeans_results_tbl <- joined_data %>%\n  left_join(sp_500_index_tbl %>% select(symbol, company, sector), by = \"symbol\" )\n\numap_kmeans_results_tbl\n\n\n\n  \n\n\n# Output: umap_kmeans_results_tbl \n\nPlot the K-Means and UMAP results.\n\nBegin with the umap_kmeans_results_tbl\n\nUse ggplot() mapping V1, V2 and color = .cluster\n\nAdd the geom_point() geometry with alpha = 0.5\n\nApply colors as you desire (e.g. scale_color_manual(values = palette_light() %>% rep(3)))\n\n\n# Visualize the combined K-Means and UMAP results\n\numap_kmeans_results_tbl %>%\n    mutate(label_text = str_glue(\"CompanyStockPrice: {symbol}\n                                 Cluster: {.cluster}\")) %>%\n    \n    ggplot(aes(V1, V2, color = .cluster)) +\n    \n    # Geometries\n    geom_point(alpta = 0.5) +\n    \n    # Formatting\n    scale_color_manual(values=c(\"#2d72d6\", \"#2dc6d6\", \"#2dd692\", \"#af9244\", \"#9d61c7\", \"#a5e461\", \"#a1306c\", \"#096f40\", \"#8d0a0c\", \"#e3792d\" )) +\n    labs(title = \"K Clustering for Stock Price Analysis\")+\n    theme(legend.position = \"none\")\n\n#> Warning in geom_point(alpta = 0.5): Ignoring unknown parameters: `alpta`"
  },
  {
    "objectID": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#congratulations-you-are-done-with-the-1st-challenge",
    "href": "content/01_journal/Challenge1/05_Machine_Learning_Fundamentals.html#congratulations-you-are-done-with-the-1st-challenge",
    "title": "Machine Learninng Fundamentals",
    "section": "\n5.7 Congratulations! You are done with the 1st challenge!",
    "text": "5.7 Congratulations! You are done with the 1st challenge!"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "",
    "text": "Load the following libraries.\n\n# Standard\nlibrary(tidyverse)\n\n# Modeling\nlibrary(parsnip)\n\n# Preprocessing & Sampling\nlibrary(recipes)\nlibrary(rsample)\n\n# Modeling Error Metrics\nlibrary(yardstick)\n\n# Plotting Decision Trees\nlibrary(rpart.plot)\n\nlibrary(forcats)\n\nlibrary(workflows)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#step-1-define-the-recipe",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#step-1-define-the-recipe",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.1 Step 1: Define the recipe",
    "text": "5.1 Step 1: Define the recipe\n\nbikes_rec <- \n  recipe(price ~ category_2 + frame_material, data = bike_orderlines_tbl) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_unknown() %>%\n  prep()"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#splitting-the-data",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#splitting-the-data",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.2 Splitting the Data",
    "text": "5.2 Splitting the Data\n\nbike_features_tbl %>% distinct(category_2)\n\n\n\n  \n\n\n# run both following commands at the same time\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(bike_features_tbl, prop   = 0.80, \n                                                       strata = \"category_2\")\n\n# Check if testing contains all category_2 values\nsplit_obj %>% training() %>% distinct(category_2)\n\n\n\n  \n\n\nsplit_obj %>% testing() %>% distinct(category_2)\n\n\n\n  \n\n\n# Assign training and test data\ntrain_tbl <- training(split_obj)\ntest_tbl  <- testing(split_obj)\n\n# We have to remove spaces and dashes from the column names\ntrain_tbl <- train_tbl %>% set_names(str_replace_all(names(train_tbl), \" |-\", \"_\"))\ntest_tbl  <- test_tbl  %>% set_names(str_replace_all(names(test_tbl),  \" |-\", \"_\"))\n\n#train_tbl$category_2 <- factor(train_tbl$category_2, levels = unique(bike_features_tbl$category_2))\n#test_tbl$category_2 <- factor(test_tbl$category_2, levels = unique(bike_features_tbl$category_2))\n\ntrain_transformed_tbl <- bake(bikes_rec, new_data = train_tbl) \ntest_transformed_tbl <- bake(bikes_rec, new_data = test_tbl) \n\n#Deleted E-Road, because there is no E-Road in the training_Tbl. Thus, it can't be trained on. (diff. levels)\n#Not Necessary, if used a recipe, due to \"step_unknown()\" function\n#test_tbl <- test_tbl[test_tbl$category_2 != \"E-Road\", ]\n\nbike_features_tbl"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-methods--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-methods--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.3 3.0 LINEAR METHODS —-",
    "text": "5.3 3.0 LINEAR METHODS —-"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-regression---no-engineered-features--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-regression---no-engineered-features--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.4 3.1 LINEAR REGRESSION - NO ENGINEERED FEATURES —-",
    "text": "5.4 3.1 LINEAR REGRESSION - NO ENGINEERED FEATURES —-\n\n# 3.1.1 Model ----\n\nmodel_01_linear_lm_simple <- linear_reg(mode = \"regression\") %>%\n    set_engine(\"lm\") #%>%\n # fit(price ~ category_2 + frame_material, data = train_tbl)\n\n\nbikes_wflow <- workflow() %>%\n  add_model(model_01_linear_lm_simple) %>%\n  add_recipe(bikes_rec)\nbikes_wflow\n\n#> ══ Workflow ════════════════════════════════════════════════════════════════════\n#> Preprocessor: Recipe\n#> Model: linear_reg()\n#> \n#> ── Preprocessor ────────────────────────────────────────────────────────────────\n#> 2 Recipe Steps\n#> \n#> • step_dummy()\n#> • step_unknown()\n#> \n#> ── Model ───────────────────────────────────────────────────────────────────────\n#> Linear Regression Model Specification (regression)\n#> \n#> Computational engine: lm\n\nbikes_fit <-\n  bikes_wflow %>%\n  fit(data = train_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#predicting-with-a-recipe",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#predicting-with-a-recipe",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.5 Predicting with a Recipe",
    "text": "5.5 Predicting with a Recipe\n\nbikes_pred <-\n  predict(bikes_fit,test_tbl)\n\n#> Warning: There are new levels in a factor: E-Road\n\nbikes_pred"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#calculating-the-common-metrics-comparing-a-truth-price-to-an-estimate-.pred.",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#calculating-the-common-metrics-comparing-a-truth-price-to-an-estimate-.pred.",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.6 Calculating the common metrics comparing a “truth” (price) to an “estimate” (.pred).",
    "text": "5.6 Calculating the common metrics comparing a “truth” (price) to an “estimate” (.pred).\n\n#model_01_linear_lm_simple %>%\n#  predict(new_data = test_tbl) %>%\nbikes_pred %>%\n\n    bind_cols(test_tbl %>% select(price)) %>%\n    \n    yardstick::metrics(truth = price, estimate = .pred)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#extracting-the-model-of-the-workflow",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#extracting-the-model-of-the-workflow",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.7 Extracting the Model of the Workflow",
    "text": "5.7 Extracting the Model of the Workflow\n\nmodel_01_linear_lm_simple <- bikes_fit %>% \n  pull_workflow_fit() #%>% \n\n#> Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.\n#> ℹ Please use `extract_fit_parsnip()` instead.\n\n # tidy()"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#model-explanation",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#model-explanation",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.8 Model Explanation",
    "text": "5.8 Model Explanation"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.9 3.1.2 Feature Importance —-",
    "text": "5.9 3.1.2 Feature Importance —-\n\n#View(model_01_linear_lm_simple) # You will see the coefficients in the element \"fit\"\n\n# tidy() function is applicable for objects with class \"lm\"\n#model_01_linear_lm_simple %>% class()\n\nmodel_01_linear_lm_simple %>%\n  broom::tidy() %>%# NOT NECESSARY with a recipe, because while extracting the model, it gets tidied already\n  arrange(p.value) %>%\n  mutate(term = as_factor(term) %>% fct_rev()) %>%\n  ggplot(aes(x = estimate, y = term)) +\n  geom_point(color = \"#2dc6d6\", size = 3) +\n  ggrepel::geom_label_repel(aes(label = scales::dollar(estimate, accuracy = 1, suffix = \" €\", prefix = \"\")),\n                            size = 4, fill = \"#272A36\", color = \"white\") +\n  scale_x_continuous(labels = scales::dollar_format(suffix = \" €\", prefix = \"\")) +\n  labs(title = \"Linear Regression: Feature Importance\",\n       subtitle = \"Model 01: Simple lm Model\")"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#function-to-calculate-metrics-without-recipe--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#function-to-calculate-metrics-without-recipe--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.10 3.1.3 Function to Calculate Metrics Without Recipe —-",
    "text": "5.10 3.1.3 Function to Calculate Metrics Without Recipe —-"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#code-we-used-earlier",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#code-we-used-earlier",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.11 Code we used earlier",
    "text": "5.11 Code we used earlier\nmodel_01_linear_lm_simple %>% predict(new_data = test_tbl) %>%\nbind_cols(test_tbl %>% select(price)) %>%\nyardstick::metrics(truth = price, estimate = .pred)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#generalized-into-a-function",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#generalized-into-a-function",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.12 Generalized into a function",
    "text": "5.12 Generalized into a function\ncalc_metrics <- function(model, new_data = test_tbl) {\nmodel %>%\n    predict(new_data = new_data) %>%\n\n    bind_cols(new_data %>% select(price)) %>%\n    yardstick::metrics(truth = price, estimate = .pred)\n}\nmodel_01_linear_lm_simple %>% calc_metrics(test_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#function-to-calculate-metrics-with-a-recipe",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#function-to-calculate-metrics-with-a-recipe",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.13 Function to Calculate Metrics With a Recipe",
    "text": "5.13 Function to Calculate Metrics With a Recipe\n\ncalc_metrics <- function(model, new_data = test_tbl) {\n\n    bikes_wflow <- workflow() %>%\n      add_model(model) %>%\n      add_recipe(bikes_rec)\n      bikes_wflow\n      \n    bikes_fit <-\n     bikes_wflow %>%\n     fit(data = train_tbl)\n    \n    bikes_pred <-\n     predict(bikes_fit,test_tbl)\n     bikes_pred\n     \n    bikes_pred %>%\n      bind_cols(test_tbl %>% select(price)) %>%\n      yardstick::metrics(truth = price, estimate = .pred)\n    \n    model <- \n     pull_workflow_fit(bikes_fit) \n}"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-regression---with-engineered-features--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#linear-regression---with-engineered-features--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.14 3.2 LINEAR REGRESSION - WITH ENGINEERED FEATURES —-",
    "text": "5.14 3.2 LINEAR REGRESSION - WITH ENGINEERED FEATURES —-\n\n# 3.2.1 Model ----\nmodel_02_linear_lm_complex <- linear_reg(\"regression\") %>%\n    set_engine(\"lm\")# %>%\n    \n    # This is going to be different. Remove unnecessary columns.\n  #  fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.15 New Recipe (Preprocessing)",
    "text": "5.15 New Recipe (Preprocessing)\n\nbikes_rec <- \n  recipe(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender))) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_unknown(all_nominal())\n\nmodel_02_linear_lm_complex <- calc_metrics(model_02_linear_lm_complex, test_tbl)\n\n#> Warning: There are new levels in a factor: E-Road\n\n\n#> Warning in predict.lm(object = object$fit, newdata = new_data, type =\n#> \"response\"): Vorhersage durch Fit ohne vollen Rang mag täuschen"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance---1",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance---1",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.16 3.2.2 Feature importance —-",
    "text": "5.16 3.2.2 Feature importance —-\n\nmodel_02_linear_lm_complex %>%\n  broom::tidy() %>%\n  arrange(p.value) %>%\n  mutate(term = as_factor(term) %>% fct_rev()) %>%\n  \n  ggplot(aes(x = estimate, y = term)) +\n  geom_point(color = \"#2dc6d6\", size = 3) +\n  ggrepel::geom_label_repel(aes(label = scales::dollar(estimate, accuracy = 1, suffix = \" €\", prefix = \"\")),\n                            size = 4, fill = \"#272A36\", color = \"white\") +\n  scale_x_continuous(labels = scales::dollar_format(suffix = \" €\", prefix = \"\")) +\n  labs(title = \"Linear Regression: Feature Importance\",\n       subtitle = \"Model 02: Complex lm Model\")\n\n#> Warning: Removed 3 rows containing missing values (`geom_point()`).\n\n\n#> Warning: Removed 3 rows containing missing values (`geom_label_repel()`)."
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#penalized-regression--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#penalized-regression--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.17 3.3 PENALIZED REGRESSION —-",
    "text": "5.17 3.3 PENALIZED REGRESSION —-\n\n# 3.3.1 Model ----\n\n\nmodel_03_linear_glmnet <- linear_reg(mode    = \"regression\", \n                                     penalty = 10, \n                                     mixture = 0.1) %>%\n    set_engine(\"glmnet\") \n   # fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))\n\n#model_03_linear_glmnet %>% calc_metrics(test_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing-1",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing-1",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.18 New Recipe (Preprocessing)",
    "text": "5.18 New Recipe (Preprocessing)\n\nbikes_rec <- \n  recipe(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender))) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_unknown(all_nominal())\n\nmodel_03_linear_glmnet <- calc_metrics(model_03_linear_glmnet, test_tbl)\n\n#> Warning: There are new levels in a factor: E-Road\n\n\n\n# 3.3.2 Feature Importance ----\nmodel_03_linear_glmnet %>%\n    broom::tidy() %>%\n    #filter(lambda >= 10 & lambda < 11) %>%\n    \n    # No p value here\n    arrange(desc(abs(estimate))) %>%\n    mutate(term = as_factor(term) %>% fct_rev()) %>%\n\n    ggplot(aes(x = estimate, y = term)) +\n    geom_point() +\n    ggrepel::geom_label_repel(aes(label = scales::dollar(estimate, accuracy = 1)),\n                              size = 2) +\n    scale_x_continuous(labels = scales::dollar_format()) +\n    labs(title = \"Linear Regression: Feature Importance\",\n         subtitle = \"Model 03: GLMNET Model\")\n\n\n\n\n\n\n\n\n# 4.0 TREE-BASED METHODS ----\n# 4.1 DECISION TREES ----\n# 4.1.1 Model ----\n\nmodel_04_tree_decision_tree <- decision_tree(mode = \"regression\",\n              \n              # Set the values accordingly to get started\n              cost_complexity = 0.001,\n              tree_depth      = 5,\n              min_n           = 7) %>%\n              \n    set_engine(\"rpart\")\n    #fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))\n\n#model_04_tree_decision_tree %>% calc_metrics(test_tbl)\nmodel_04_tree_decision_tree <- calc_metrics(model_04_tree_decision_tree, test_tbl)\n\n#> Warning: There are new levels in a factor: E-Road"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#decision-tree-plot--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#decision-tree-plot--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.19 4.1.2 Decision Tree Plot —-",
    "text": "5.19 4.1.2 Decision Tree Plot —-\n\nmodel_04_tree_decision_tree$fit %>%\n    rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n# Optimze plot\nmodel_04_tree_decision_tree$fit %>%\n    rpart.plot(\n        roundint = FALSE,\n        type = 4,\n        extra = 101, # see help page\n        fallen.leaves = FALSE, # changes the angles from 90 to 45-degree\n        cex = 0.6, # font size\n        main = \"Model 04: Decision Tree\", # Adds title\n        box.palette = \"Blues\",\n        box.col = \"lightblue\"\n        )\n\n#> Warning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\nshow.prp.palettes()"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#xgboost--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#xgboost--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.20 4.3 XGBOOST —-",
    "text": "5.20 4.3 XGBOOST —-"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#model--",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#model--",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.21 4.3.1 Model —-",
    "text": "5.21 4.3.1 Model —-\n\nset.seed(1234)\nmodel_07_boost_tree_xgboost <- boost_tree(\n    mode = \"regression\",\n    mtry = 30,\n    learn_rate = 0.25,\n    tree_depth = 7\n    ) %>%\n    set_engine(\"xgboost\")\n   # fit(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender)))"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing-2",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#new-recipe-preprocessing-2",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.22 New Recipe (Preprocessing)",
    "text": "5.22 New Recipe (Preprocessing)\n\nbikes_rec <- \n  recipe(price ~ ., data = train_tbl %>% select(-c(id:weight), -category_1, -c(category_3:gender))) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_unknown(all_nominal())\n\nmodel_07_boost_tree_xgboost <- calc_metrics(model_07_boost_tree_xgboost, test_tbl)\n\n#> Warning: There are new levels in a factor: E-Road\n\n#model_07_boost_tree_xgboost %>% calc_metrics(test_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance---2",
    "href": "content/01_journal/Challenge2/Chapter_2_Challenge.html#feature-importance---2",
    "title": "Session 6 - Challenge - Company Segmentation",
    "section": "\n5.23 4.3.2 Feature Importance —-",
    "text": "5.23 4.3.2 Feature Importance —-\n\nmodel_07_boost_tree_xgboost$fit %>%\n    xgboost::xgb.importance(model = .) %>%\n    as_tibble() %>%\n    arrange(desc(Gain)) %>%\n    mutate(Feature = as_factor(Feature) %>% fct_rev()) %>%\n\n    ggplot(aes(Gain, Feature)) +\n    geom_point() +\n    labs(\n        title = \"XGBoost: Variable Importance\",\n        subtitle = \"Model 07: XGBoost Model\"\n    )"
  },
  {
    "objectID": "content/01_journal/Challenge3/Challenge3.html",
    "href": "content/01_journal/Challenge3/Challenge3.html",
    "title": "Challenge3",
    "section": "",
    "text": "library (h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n\n\n#> \n#> Attache Paket: 'h2o'\n\n\n#> Die folgenden Objekte sind maskiert von 'package:stats':\n#> \n#>     cor, sd, var\n\n\n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1\n\n\n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\nlibrary(skimr)\n\nlibrary(GGally)\n\n#> Registered S3 method overwritten by 'GGally':\n#>   method from   \n#>   +.gg   ggplot2"
  },
  {
    "objectID": "content/01_journal/Challenge3/Challenge3.html#section-1",
    "href": "content/01_journal/Challenge3/Challenge3.html#section-1",
    "title": "Challenge3",
    "section": "\n0.2 ",
    "text": "0.2 \nYou can also embed plots, for example:\n\nh2o.init()\n\n#> \n#> H2O is not running yet, starting it now...\n#> \n#> Note:  In case of errors look at the following log files:\n#>     C:\\Users\\tiend\\AppData\\Local\\Temp\\RtmpU7xkOO\\file304382a5842/h2o_tiend_started_from_r.out\n#>     C:\\Users\\tiend\\AppData\\Local\\Temp\\RtmpU7xkOO\\file304e3d5168/h2o_tiend_started_from_r.err\n#> \n#> \n#> Starting H2O JVM and connecting:  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         1 seconds 896 milliseconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 21 days \n#>     H2O cluster name:           H2O_started_from_R_tiend_htd163 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.99 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 21 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n\n\nhp_by_cyl <- mtcars %>% \n  group_by(cyl) %>%\n  summarize(min_hp=min(hp),\n            max_hp=max(hp))\nhp_by_cyl\n\n\n\n  \n\n\n\n\ngroupby_var <- quo(vs)\n\nhp_by_vs <- mtcars %>% \n              group_by(!!groupby_var) %>%\n              summarize(min_hp=min(hp),\n                        max_hp=max(hp))\nhp_by_vs\n\n\n\n  \n\n\n\n\ncar_stats <- function(groupby_var, measure_var) {\n\n    groupby_var <- enquo(groupby_var)\n    measure_var <- enquo(measure_var)\n    \n    ret <- mtcars %>% \n      \n             group_by(!!groupby_var) %>%\n             summarize(min = min(!!measure_var), max = max(!!measure_var)) %>%\n      \n             # Optional: as_label() and \"walrus operator\" :=\n             mutate(\n               measure_var = as_label(measure_var), !!measure_var := \"test\"\n               )\n    \n    return(ret)\n\n}\ncar_stats(am,hp)\n\n\n\n  \n\n\ncar_stats(gear,cyl)\n\n\n\n  \n\n\n\n\nscatter_plot <- function(data, x_var, y_var) {\n  \n  x_var <- enquo(x_var)\n  y_var <- enquo(y_var)\n  \n  ret <- data %>% \n           ggplot(aes(x = !!x_var, y = !!y_var)) + \n           geom_point() + \n           geom_smooth() +\n           ggtitle(str_c(as_label(y_var), \" vs. \",as_label(x_var)))\n \n  return(ret)\n}\nscatter_plot(mtcars, disp, hp)\n\n#> `geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/Challenge3/Challenge3.html#data-understanding",
    "href": "content/01_journal/Challenge3/Challenge3.html#data-understanding",
    "title": "Challenge3",
    "section": "\n7.1 2. Data Understanding",
    "text": "7.1 2. Data Understanding"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html",
    "href": "content/01_journal/Challenge4/Challenge4.html",
    "title": "Challenge4",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\n# libraries\nlibrary(rsample)\nlibrary(recipes)\n\n#> \n#> Attache Paket: 'recipes'\n#> \n#> Das folgende Objekt ist maskiert 'package:stringr':\n#> \n#>     fixed\n#> \n#> Das folgende Objekt ist maskiert 'package:stats':\n#> \n#>     step\n\nlibrary(PerformanceAnalytics)  # for skewness \n\n#> Lade nötiges Paket: xts\n#> Lade nötiges Paket: zoo\n#> \n#> Attache Paket: 'zoo'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> \n#> ######################### Warning from 'xts' package ##########################\n#> #                                                                             #\n#> # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#> # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#> # source() into this session won't work correctly.                            #\n#> #                                                                             #\n#> # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#> # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#> # dplyr from breaking base R's lag() function.                                #\n#> #                                                                             #\n#> # Code in packages is not affected. It's protected by R's namespace mechanism #\n#> # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#> #                                                                             #\n#> ###############################################################################\n#> \n#> Attache Paket: 'xts'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:dplyr':\n#> \n#>     first, last\n#> \n#> \n#> Attache Paket: 'PerformanceAnalytics'\n#> \n#> Das folgende Objekt ist maskiert 'package:graphics':\n#> \n#>     legend\n\n# H2O modeling\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n#> \n#> \n#> Attache Paket: 'h2o'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:lubridate':\n#> \n#>     day, hour, month, week, year\n#> \n#> Die folgenden Objekte sind maskiert von 'package:stats':\n#> \n#>     cor, sd, var\n#> \n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\n\n\n# Load data\n\nemployee_attrition_tbl <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n#> Rows: 1470 Columns: 35\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#> dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndefinitions_raw_tbl    <- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n\n#> New names:\n#> • `` -> `...1`\n#> • `` -> `...2`\n\nView(definitions_raw_tbl)\n\n\nemployee_attrition_tbl %>% \n        ggplot(aes(Education)) +\n        geom_bar()"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#load-the-training-test-dataset",
    "href": "content/01_journal/Challenge4/Challenge4.html#load-the-training-test-dataset",
    "title": "Challenge4",
    "section": "\n18.1 1. Load the training & test dataset",
    "text": "18.1 1. Load the training & test dataset\n\nproduct_backorder_tbl          <- read_csv(\"product_backorders.csv\")\n\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#specifiy-the-response-and-predictor-variables",
    "href": "content/01_journal/Challenge4/Challenge4.html#specifiy-the-response-and-predictor-variables",
    "title": "Challenge4",
    "section": "\n18.2 2. Specifiy the response and predictor variables",
    "text": "18.2 2. Specifiy the response and predictor variables\n\nset.seed(seed = 1113)\nsplit_obj                       <- rsample::initial_split(product_backorder_tbl, prop = 0.85)\ntrain_readable_tbl              <- training(split_obj)\ntest_readable_tbl               <- testing(split_obj)\n\nrecipe_obj <- recipe(went_on_backorder ~., data = train_readable_tbl) %>% \n    step_zv(all_predictors()) %>% \n    prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#modeling-1",
    "href": "content/01_journal/Challenge4/Challenge4.html#modeling-1",
    "title": "Challenge4",
    "section": "\n18.3 Modeling",
    "text": "18.3 Modeling\n\nh2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         8 minutes 7 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 21 days \n#>     H2O cluster name:           H2O_started_from_R_tiend_htd163 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.93 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 21 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Set the target and predictors\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#run-automl-specifying-the-stopping-criterion",
    "href": "content/01_journal/Challenge4/Challenge4.html#run-automl-specifying-the-stopping-criterion",
    "title": "Challenge4",
    "section": "\n18.4 3. Run AutoML specifying the stopping criterion",
    "text": "18.4 3. Run AutoML specifying the stopping criterion\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 17:19:48.634: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 17:19:48.637: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#view-the-leaderboard",
    "href": "content/01_journal/Challenge4/Challenge4.html#view-the-leaderboard",
    "title": "Challenge4",
    "section": "\n18.5 4. View the leaderboard",
    "text": "18.5 4. View the leaderboard\n\ntypeof(automl_models_h2o)\n\n#> [1] \"S4\"\n\n## \"S4\"\n\nslotNames(automl_models_h2o)\n\n#> [1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"     \n#> [5] \"modeling_steps\" \"training_info\"\n\n## [1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"      \"modeling_steps\" \"training_info\" \n\nautoml_models_h2o@leaderboard\n\n#>                                                  model_id       auc   logloss\n#> 1 StackedEnsemble_BestOfFamily_3_AutoML_2_20230530_171948 0.9505346 0.1737436\n#> 2    StackedEnsemble_AllModels_2_AutoML_2_20230530_171948 0.9504264 0.1743102\n#> 3    StackedEnsemble_AllModels_1_AutoML_2_20230530_171948 0.9497656 0.1748509\n#> 4 StackedEnsemble_BestOfFamily_2_AutoML_2_20230530_171948 0.9495534 0.1746771\n#> 5                          GBM_4_AutoML_2_20230530_171948 0.9491389 0.1771911\n#> 6                          GBM_2_AutoML_2_20230530_171948 0.9461516 0.1818330\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7473453            0.1416139 0.2284028 0.05216786\n#> 2 0.7456369            0.1398390 0.2294578 0.05265090\n#> 3 0.7458891            0.1400992 0.2295994 0.05271588\n#> 4 0.7465168            0.1455766 0.2286653 0.05228784\n#> 5 0.7459758            0.1519872 0.2301827 0.05298410\n#> 6 0.7322194            0.1442607 0.2326821 0.05414098\n#> \n#> [14 rows x 7 columns]\n\n##                                              model_id       auc   logloss     aucpr mean_per_class_error      rmse        mse\n## 1 StackedEnsemble_BestOfFamily_AutoML_20200820_190823 0.8585439 0.2992854 0.5869929            0.2406915 0.2978416 0.08870964\n## 2          GBM_grid__1_AutoML_20200820_190823_model_3 0.8494016 0.3137896 0.5165541            0.2386968 0.3098134 0.09598435\n## 3 DeepLearning_grid__1_AutoML_20200820_190823_model_1 0.8479056 0.3066365 0.6154288            0.2583112 0.3071528 0.09434283\n## 4      XGBoost_grid__1_AutoML_20200820_190823_model_5 0.8439162 0.3057109 0.5299331            0.2061170 0.3071419 0.09433613\n## 5    StackedEnsemble_AllModels_AutoML_20200820_190823 0.8425864 0.3211612 0.5205591            0.2539894 0.3107399 0.09655928\n## 6      XGBoost_grid__1_AutoML_20200820_190823_model_6 0.8257979 0.3211936 0.5009608            0.2536569 0.3111129 0.09679122\n##\n## [30 rows x 7 columns] \n\nautoml_models_h2o@leader\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: stackedensemble\n#> Model ID:  StackedEnsemble_BestOfFamily_3_AutoML_2_20230530_171948 \n#> Model Summary for Stacked Ensemble: \n#>                                          key            value\n#> 1                          Stacking strategy cross_validation\n#> 2       Number of base models (used / total)              4/5\n#> 3           # GBM base models (used / total)              1/1\n#> 4           # DRF base models (used / total)              2/2\n#> 5           # GLM base models (used / total)              1/1\n#> 6  # DeepLearning base models (used / total)              0/1\n#> 7                      Metalearner algorithm              GLM\n#> 8         Metalearner fold assignment scheme           Random\n#> 9                         Metalearner nfolds                5\n#> 10                   Metalearner fold_column               NA\n#> 11        Custom metalearner hyperparameters             None\n#> \n#> \n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on training data. **\n#> \n#> MSE:  0.02054818\n#> RMSE:  0.1433464\n#> LogLoss:  0.08107618\n#> Mean Per-Class Error:  0.06990433\n#> AUC:  0.9938292\n#> AUCPR:  0.9633379\n#> Gini:  0.9876584\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No  Yes    Error        Rate\n#> No     8772   74 0.008365    =74/8846\n#> Yes     153 1011 0.131443   =153/1164\n#> Totals 8925 1085 0.022677  =227/10010\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.484917    0.899066 158\n#> 2                       max f2  0.316263    0.915022 207\n#> 3                 max f0point5  0.615807    0.924437 127\n#> 4                 max accuracy  0.484917    0.977323 158\n#> 5                max precision  0.999648    1.000000   0\n#> 6                   max recall  0.036393    1.000000 332\n#> 7              max specificity  0.999648    1.000000   0\n#> 8             max absolute_mcc  0.484917    0.887005 158\n#> 9   max min_per_class_accuracy  0.224396    0.957495 236\n#> 10 max mean_per_class_accuracy  0.258559    0.959372 225\n#> 11                     max tns  0.999648 8846.000000   0\n#> 12                     max fns  0.999648 1163.000000   0\n#> 13                     max fps  0.000130 8846.000000 399\n#> 14                     max tps  0.036393 1164.000000 332\n#> 15                     max tnr  0.999648    1.000000   0\n#> 16                     max fnr  0.999648    0.999141   0\n#> 17                     max fpr  0.000130    1.000000 399\n#> 18                     max tpr  0.036393    1.000000 332\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.04883593\n#> RMSE:  0.2209885\n#> LogLoss:  0.1635604\n#> Mean Per-Class Error:  0.11121\n#> AUC:  0.9548621\n#> AUCPR:  0.7749467\n#> Gini:  0.9097243\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     1962 142 0.067490  =142/2104\n#> Yes      44 240 0.154930    =44/284\n#> Totals 2006 382 0.077889  =186/2388\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.213240    0.720721 216\n#> 2                       max f2  0.181262    0.794574 231\n#> 3                 max f0point5  0.685374    0.748945  92\n#> 4                 max accuracy  0.502370    0.935092 131\n#> 5                max precision  0.974913    1.000000   0\n#> 6                   max recall  0.001056    1.000000 396\n#> 7              max specificity  0.974913    1.000000   0\n#> 8             max absolute_mcc  0.213240    0.686641 216\n#> 9   max min_per_class_accuracy  0.123432    0.893536 259\n#> 10 max mean_per_class_accuracy  0.108938    0.898952 268\n#> 11                     max tns  0.974913 2104.000000   0\n#> 12                     max fns  0.974913  283.000000   0\n#> 13                     max fps  0.000139 2104.000000 399\n#> 14                     max tps  0.001056  284.000000 396\n#> 15                     max tnr  0.974913    1.000000   0\n#> 16                     max fnr  0.974913    0.996479   0\n#> 17                     max fpr  0.000139    1.000000 399\n#> 18                     max tpr  0.001056    1.000000 396\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05055507\n#> RMSE:  0.2248445\n#> LogLoss:  0.1706878\n#> Mean Per-Class Error:  0.1433012\n#> AUC:  0.9518013\n#> AUCPR:  0.7386671\n#> Gini:  0.9036025\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error         Rate\n#> No     11549  620 0.050949   =620/12169\n#> Yes      386 1252 0.235653    =386/1638\n#> Totals 11935 1872 0.072862  =1006/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.312093     0.713390 213\n#> 2                       max f2  0.140938     0.775459 275\n#> 3                 max f0point5  0.521195     0.729439 146\n#> 4                 max accuracy  0.521195     0.931846 146\n#> 5                max precision  0.984104     1.000000   0\n#> 6                   max recall  0.000199     1.000000 399\n#> 7              max specificity  0.984104     1.000000   0\n#> 8             max absolute_mcc  0.312093     0.673832 213\n#> 9   max min_per_class_accuracy  0.116669     0.884132 288\n#> 10 max mean_per_class_accuracy  0.092947     0.888155 301\n#> 11                     max tns  0.984104 12169.000000   0\n#> 12                     max fns  0.984104  1635.000000   0\n#> 13                     max fps  0.000199 12169.000000 399\n#> 14                     max tps  0.000199  1638.000000 399\n#> 15                     max tnr  0.984104     1.000000   0\n#> 16                     max fnr  0.984104     0.998168   0\n#> 17                     max fpr  0.000199     1.000000 399\n#> 18                     max tpr  0.000199     1.000000 399\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                 mean        sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\n#> accuracy    0.933691  0.004650   0.936681   0.937982   0.928261   0.929028\n#> auc         0.952260  0.003238   0.955320   0.947773   0.952744   0.950307\n#> err         0.066309  0.004650   0.063319   0.062018   0.071739   0.070972\n#> err_count 183.200000 14.618482 174.000000 169.000000 198.000000 200.000000\n#> f0point5    0.720742  0.010939   0.704380   0.722295   0.733896   0.717439\n#>           cv_5_valid\n#> accuracy    0.936502\n#> auc         0.955155\n#> err         0.063498\n#> err_count 175.000000\n#> f0point5    0.725699\n#> \n#> ---\n#>                         mean        sd cv_1_valid cv_2_valid  cv_3_valid\n#> precision           0.723492  0.009172   0.714815   0.722772    0.731579\n#> r2                  0.515232  0.016789   0.492489   0.506611    0.527326\n#> recall              0.710766  0.031044   0.665517   0.720395    0.743316\n#> residual_deviance 942.476560 64.836500 882.500200 915.867900 1016.921450\n#> rmse                0.224683  0.008198   0.218875   0.221138    0.235311\n#> specificity         0.963327  0.005457   0.968674   0.965304    0.957251\n#>                    cv_4_valid cv_5_valid\n#> precision            0.714286   0.734007\n#> r2                   0.514771   0.534966\n#> recall               0.730337   0.694268\n#> residual_deviance 1007.258500 889.834700\n#> rmse                 0.231420   0.216671\n#> specificity          0.957758   0.967649\n\nsource(\"extract_h2o_model_name_by_position.R\")\n\nmodel <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(6) %>% \n  h2o.getModel()\n\n#> GBM_2_AutoML_2_20230530_171948\n\nmodel\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: gbm\n#> Model ID:  GBM_2_AutoML_2_20230530_171948 \n#> Model Summary: \n#>   number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n#> 1              79                       79               58865         7\n#>   max_depth mean_depth min_leaves max_leaves mean_leaves\n#> 1         7    7.00000         28         87    54.54430\n#> \n#> \n#> H2OBinomialMetrics: gbm\n#> ** Reported on training data. **\n#> \n#> MSE:  0.03693381\n#> RMSE:  0.1921817\n#> LogLoss:  0.1315131\n#> Mean Per-Class Error:  0.1134932\n#> AUC:  0.9770072\n#> AUCPR:  0.8820287\n#> Gini:  0.9540143\n#> R^2:  0.6467729\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error        Rate\n#> No     11799  370 0.030405  =370/12169\n#> Yes      322 1316 0.196581   =322/1638\n#> Totals 12121 1686 0.050120  =692/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.358069     0.791817 194\n#> 2                       max f2  0.168777     0.839282 260\n#> 3                 max f0point5  0.574337     0.836861 128\n#> 4                 max accuracy  0.458721     0.953067 163\n#> 5                max precision  0.990870     1.000000   0\n#> 6                   max recall  0.020975     1.000000 365\n#> 7              max specificity  0.990870     1.000000   0\n#> 8             max absolute_mcc  0.458721     0.764575 163\n#> 9   max min_per_class_accuracy  0.163320     0.921851 263\n#> 10 max mean_per_class_accuracy  0.146505     0.922623 271\n#> 11                     max tns  0.990870 12169.000000   0\n#> 12                     max fns  0.990870  1635.000000   0\n#> 13                     max fps  0.001663 12169.000000 399\n#> 14                     max tps  0.020975  1638.000000 365\n#> 15                     max tnr  0.990870     1.000000   0\n#> 16                     max fnr  0.990870     0.998168   0\n#> 17                     max fpr  0.001663     1.000000 399\n#> 18                     max tpr  0.020975     1.000000 365\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.05128636\n#> RMSE:  0.2264649\n#> LogLoss:  0.1738922\n#> Mean Per-Class Error:  0.167277\n#> AUC:  0.9496666\n#> AUCPR:  0.7478056\n#> Gini:  0.8993333\n#> R^2:  0.5105521\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     2015  89 0.042300   =89/2104\n#> Yes      83 201 0.292254    =83/284\n#> Totals 2098 290 0.072027  =172/2388\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.322531    0.700348 178\n#> 2                       max f2  0.096387    0.788849 275\n#> 3                 max f0point5  0.560464    0.739300 114\n#> 4                 max accuracy  0.517464    0.931323 124\n#> 5                max precision  0.919562    0.950000  12\n#> 6                   max recall  0.005847    1.000000 387\n#> 7              max specificity  0.988848    0.999525   0\n#> 8             max absolute_mcc  0.322531    0.659467 178\n#> 9   max min_per_class_accuracy  0.125340    0.886882 259\n#> 10 max mean_per_class_accuracy  0.096387    0.900819 275\n#> 11                     max tns  0.988848 2103.000000   0\n#> 12                     max fns  0.988848  284.000000   0\n#> 13                     max fps  0.001380 2104.000000 399\n#> 14                     max tps  0.005847  284.000000 387\n#> 15                     max tnr  0.988848    0.999525   0\n#> 16                     max fnr  0.988848    1.000000   0\n#> 17                     max fpr  0.001380    1.000000 399\n#> 18                     max tpr  0.005847    1.000000 387\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.0528744\n#> RMSE:  0.2299443\n#> LogLoss:  0.1778463\n#> Mean Per-Class Error:  0.1567967\n#> AUC:  0.9477685\n#> AUCPR:  0.7219702\n#> Gini:  0.895537\n#> R^2:  0.4943206\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error         Rate\n#> No     11540  629 0.051689   =629/12169\n#> Yes      429 1209 0.261905    =429/1638\n#> Totals 11969 1838 0.076628  =1058/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.311909     0.695627 209\n#> 2                       max f2  0.140433     0.772742 271\n#> 3                 max f0point5  0.550250     0.712464 133\n#> 4                 max accuracy  0.458730     0.927935 163\n#> 5                max precision  0.941922     0.917647  12\n#> 6                   max recall  0.005248     1.000000 390\n#> 7              max specificity  0.990527     0.999836   0\n#> 8             max absolute_mcc  0.210319     0.654543 243\n#> 9   max min_per_class_accuracy  0.118016     0.884005 281\n#> 10 max mean_per_class_accuracy  0.123093     0.885131 278\n#> 11                     max tns  0.990527 12167.000000   0\n#> 12                     max fns  0.990527  1637.000000   0\n#> 13                     max fps  0.001135 12169.000000 399\n#> 14                     max tps  0.005248  1638.000000 390\n#> 15                     max tnr  0.990527     0.999836   0\n#> 16                     max fnr  0.990527     0.999389   0\n#> 17                     max fpr  0.001135     1.000000 399\n#> 18                     max tpr  0.005248     1.000000 390\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                               mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> accuracy                  0.923879  0.007712   0.934106   0.921434   0.913437\n#> auc                       0.947629  0.005585   0.956067   0.950016   0.942757\n#> err                       0.076121  0.007712   0.065894   0.078566   0.086563\n#> err_count               210.200000 21.276749 182.000000 217.000000 239.000000\n#> f0point5                  0.674673  0.045738   0.745614   0.642154   0.630631\n#> f1                        0.704026  0.025595   0.749311   0.695652   0.690013\n#> f2                        0.738167  0.027362   0.753045   0.758874   0.761741\n#> lift_top_group            7.223031  0.206073   7.398214   7.390181   6.978352\n#> logloss                   0.177847  0.006413   0.173788   0.169361   0.185843\n#> max_per_class_error       0.235707  0.047688   0.244444   0.192182   0.181538\n#> mcc                       0.665015  0.026497   0.711414   0.659935   0.651993\n#> mean_per_class_accuracy   0.854892  0.018180   0.858211   0.871730   0.872285\n#> mean_per_class_error      0.145108  0.018180   0.141789   0.128270   0.127715\n#> mse                       0.052875  0.002157   0.051792   0.050311   0.056156\n#> pr_auc                    0.721481  0.031318   0.772316   0.715135   0.687817\n#> precision                 0.657237  0.059358   0.743169   0.610837   0.596413\n#> r2                        0.493179  0.030582   0.543083   0.490760   0.459285\n#> recall                    0.764293  0.047688   0.755556   0.807818   0.818462\n#> rmse                      0.229907  0.004672   0.227579   0.224302   0.236973\n#> specificity               0.945491  0.014542   0.960866   0.935642   0.926108\n#>                         cv_4_valid cv_5_valid\n#> accuracy                  0.922492   0.927925\n#> auc                       0.942862   0.946445\n#> err                       0.077508   0.072075\n#> err_count               214.000000 199.000000\n#> f0point5                  0.664789   0.690175\n#> f1                        0.688047   0.697108\n#> f2                        0.712991   0.704182\n#> lift_top_group            7.326847   7.021561\n#> logloss                   0.181057   0.179186\n#> max_per_class_error       0.269350   0.291022\n#> mcc                       0.645398   0.656335\n#> mean_per_class_accuracy   0.839279   0.832955\n#> mean_per_class_error      0.160721   0.167045\n#> mse                       0.052918   0.053196\n#> pr_auc                    0.723381   0.708756\n#> precision                 0.650138   0.685629\n#> r2                        0.487733   0.485036\n#> recall                    0.730650   0.708978\n#> rmse                      0.230038   0.230643\n#> specificity               0.947908   0.956932"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#predictions",
    "href": "content/01_journal/Challenge4/Challenge4.html#predictions",
    "title": "Challenge4",
    "section": "\n18.6 5. Predictions",
    "text": "18.6 5. Predictions\n\npredictions <- h2o.predict(model, newdata = as.h2o(test_tbl))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\npredictions\n\n#>   predict        No       Yes\n#> 1     Yes 0.3393299 0.6606701\n#> 2     Yes 0.3782626 0.6217374\n#> 3     Yes 0.4287946 0.5712054\n#> 4     Yes 0.4445579 0.5554421\n#> 5     Yes 0.2230338 0.7769662\n#> 6     Yes 0.5734233 0.4265767\n#> \n#> [2858 rows x 3 columns]"
  },
  {
    "objectID": "content/01_journal/Challenge4/Challenge4.html#save-the-leader-model",
    "href": "content/01_journal/Challenge4/Challenge4.html#save-the-leader-model",
    "title": "Challenge4",
    "section": "\n18.7 6. Save the leader model",
    "text": "18.7 6. Save the leader model\n\nmodel %>% h2o.saveModel(path = \"04_Modeling/h20_models/\")\n\n#> [1] \"C:\\\\Users\\\\tiend\\\\Documents\\\\GitHub\\\\ss23-bdml-tiend96\\\\content\\\\01_journal\\\\Challenge3\\\\04_Modeling\\\\h20_models\\\\GBM_2_AutoML_2_20230530_171948\""
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html",
    "href": "content/01_journal/Challenge5/Challenge5.html",
    "title": "Challenge5",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\n#Load Libraries\n\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.2     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.1     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readxl)\n\n# libraries\nlibrary(rsample)\nlibrary(recipes)\n\n#> \n#> Attache Paket: 'recipes'\n#> \n#> Das folgende Objekt ist maskiert 'package:stringr':\n#> \n#>     fixed\n#> \n#> Das folgende Objekt ist maskiert 'package:stats':\n#> \n#>     step\n\nlibrary(PerformanceAnalytics)  # for skewness \n\n#> Lade nötiges Paket: xts\n#> Lade nötiges Paket: zoo\n#> \n#> Attache Paket: 'zoo'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> \n#> ######################### Warning from 'xts' package ##########################\n#> #                                                                             #\n#> # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#> # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#> # source() into this session won't work correctly.                            #\n#> #                                                                             #\n#> # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#> # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#> # dplyr from breaking base R's lag() function.                                #\n#> #                                                                             #\n#> # Code in packages is not affected. It's protected by R's namespace mechanism #\n#> # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#> #                                                                             #\n#> ###############################################################################\n#> \n#> Attache Paket: 'xts'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:dplyr':\n#> \n#>     first, last\n#> \n#> \n#> Attache Paket: 'PerformanceAnalytics'\n#> \n#> Das folgende Objekt ist maskiert 'package:graphics':\n#> \n#>     legend\n\n# H2O modeling\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n#> \n#> \n#> Attache Paket: 'h2o'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:lubridate':\n#> \n#>     day, hour, month, week, year\n#> \n#> Die folgenden Objekte sind maskiert von 'package:stats':\n#> \n#>     cor, sd, var\n#> \n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#load-the-training-test-dataset",
    "href": "content/01_journal/Challenge5/Challenge5.html#load-the-training-test-dataset",
    "title": "Challenge5",
    "section": "\n10.1 1. Load the training & test dataset",
    "text": "10.1 1. Load the training & test dataset\n\nproduct_backorder_tbl          <- read_csv(\"product_backorders.csv\")\n\n#> Rows: 19053 Columns: 23\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (7): potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_bu...\n#> dbl (16): sku, national_inv, lead_time, in_transit_qty, forecast_3_month, fo...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#specifiy-the-response-and-predictor-variables",
    "href": "content/01_journal/Challenge5/Challenge5.html#specifiy-the-response-and-predictor-variables",
    "title": "Challenge5",
    "section": "\n10.2 2. Specifiy the response and predictor variables",
    "text": "10.2 2. Specifiy the response and predictor variables\n\nset.seed(seed = 1113)\nsplit_obj                       <- rsample::initial_split(product_backorder_tbl, prop = 0.85)\ntrain_readable_tbl              <- training(split_obj)\ntest_readable_tbl               <- testing(split_obj)\n\nrecipe_obj <- recipe(went_on_backorder ~., data = train_readable_tbl) %>% \n    step_zv(all_predictors()) %>% \n    prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#modeling-1",
    "href": "content/01_journal/Challenge5/Challenge5.html#modeling-1",
    "title": "Challenge5",
    "section": "\n10.3 Modeling",
    "text": "10.3 Modeling\n\nh2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         11 minutes 11 seconds \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 21 days \n#>     H2O cluster name:           H2O_started_from_R_tiend_drs368 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   3.48 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 21 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\n# Split data into a training and a validation data frame\n# Setting the seed is just for reproducability\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n# Set the target and predictors\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#run-automl-specifying-the-stopping-criterion",
    "href": "content/01_journal/Challenge5/Challenge5.html#run-automl-specifying-the-stopping-criterion",
    "title": "Challenge5",
    "section": "\n10.4 3. Run AutoML specifying the stopping criterion",
    "text": "10.4 3. Run AutoML specifying the stopping criterion\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n#> 17:54:39.295: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n#> 17:54:39.296: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#view-the-leaderboard",
    "href": "content/01_journal/Challenge5/Challenge5.html#view-the-leaderboard",
    "title": "Challenge5",
    "section": "\n10.5 4. View the leaderboard",
    "text": "10.5 4. View the leaderboard\n\ntypeof(automl_models_h2o)\n\n#> [1] \"S4\"\n\n## \"S4\"\n\nslotNames(automl_models_h2o)\n\n#> [1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"     \n#> [5] \"modeling_steps\" \"training_info\"\n\n## [1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"      \"modeling_steps\" \"training_info\" \n\nautoml_models_h2o@leaderboard\n\n#>                                                  model_id       auc   logloss\n#> 1                          GBM_4_AutoML_5_20230530_175439 0.9508884 0.1750208\n#> 2 StackedEnsemble_BestOfFamily_3_AutoML_5_20230530_175439 0.9503594 0.1729756\n#> 3 StackedEnsemble_BestOfFamily_2_AutoML_5_20230530_175439 0.9501189 0.1736990\n#> 4    StackedEnsemble_AllModels_2_AutoML_5_20230530_175439 0.9495251 0.1743236\n#> 5    StackedEnsemble_AllModels_1_AutoML_5_20230530_175439 0.9490799 0.1749026\n#> 6                          GBM_3_AutoML_5_20230530_175439 0.9458353 0.1799821\n#>       aucpr mean_per_class_error      rmse        mse\n#> 1 0.7599759            0.1745550 0.2295620 0.05269870\n#> 2 0.7595392            0.1544814 0.2279107 0.05194327\n#> 3 0.7543256            0.1571282 0.2283527 0.05214494\n#> 4 0.7534890            0.1472903 0.2290302 0.05245481\n#> 5 0.7500123            0.1451176 0.2293033 0.05258002\n#> 6 0.7393275            0.1229475 0.2311978 0.05345241\n#> \n#> [16 rows x 7 columns]\n\n##                                              model_id       auc   logloss     aucpr mean_per_class_error      rmse        mse\n## 1 StackedEnsemble_BestOfFamily_AutoML_20200820_190823 0.8585439 0.2992854 0.5869929            0.2406915 0.2978416 0.08870964\n## 2          GBM_grid__1_AutoML_20200820_190823_model_3 0.8494016 0.3137896 0.5165541            0.2386968 0.3098134 0.09598435\n## 3 DeepLearning_grid__1_AutoML_20200820_190823_model_1 0.8479056 0.3066365 0.6154288            0.2583112 0.3071528 0.09434283\n## 4      XGBoost_grid__1_AutoML_20200820_190823_model_5 0.8439162 0.3057109 0.5299331            0.2061170 0.3071419 0.09433613\n## 5    StackedEnsemble_AllModels_AutoML_20200820_190823 0.8425864 0.3211612 0.5205591            0.2539894 0.3107399 0.09655928\n## 6      XGBoost_grid__1_AutoML_20200820_190823_model_6 0.8257979 0.3211936 0.5009608            0.2536569 0.3111129 0.09679122\n##\n## [30 rows x 7 columns] \n\nautoml_models_h2o@leader\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: gbm\n#> Model ID:  GBM_4_AutoML_5_20230530_175439 \n#> Model Summary: \n#>   number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n#> 1              59                       59              121213        10\n#>   max_depth mean_depth min_leaves max_leaves mean_leaves\n#> 1        10   10.00000         43        256   158.61017\n#> \n#> \n#> H2OBinomialMetrics: gbm\n#> ** Reported on training data. **\n#> \n#> MSE:  0.0233155\n#> RMSE:  0.1526941\n#> LogLoss:  0.09112173\n#> Mean Per-Class Error:  0.06724254\n#> AUC:  0.9920052\n#> AUCPR:  0.956682\n#> Gini:  0.9840104\n#> R^2:  0.7770156\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error        Rate\n#> No     11996  173 0.014216  =173/12169\n#> Yes      197 1441 0.120269   =197/1638\n#> Totals 12193 1614 0.026798  =370/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.401949     0.886224 187\n#> 2                       max f2  0.232500     0.906330 237\n#> 3                 max f0point5  0.573163     0.912836 139\n#> 4                 max accuracy  0.401949     0.973202 187\n#> 5                max precision  0.986680     1.000000   0\n#> 6                   max recall  0.015457     1.000000 366\n#> 7              max specificity  0.986680     1.000000   0\n#> 8             max absolute_mcc  0.401949     0.871068 187\n#> 9   max min_per_class_accuracy  0.201774     0.955214 248\n#> 10 max mean_per_class_accuracy  0.210165     0.956069 245\n#> 11                     max tns  0.986680 12169.000000   0\n#> 12                     max fns  0.986680  1633.000000   0\n#> 13                     max fps  0.001396 12169.000000 399\n#> 14                     max tps  0.015457  1638.000000 366\n#> 15                     max tnr  0.986680     1.000000   0\n#> 16                     max fnr  0.986680     0.996947   0\n#> 17                     max fpr  0.001396     1.000000 399\n#> 18                     max tpr  0.015457     1.000000 366\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.05125612\n#> RMSE:  0.2263981\n#> LogLoss:  0.1720632\n#> Mean Per-Class Error:  0.1357709\n#> AUC:  0.9509243\n#> AUCPR:  0.738279\n#> Gini:  0.9018486\n#> R^2:  0.5108407\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     1992 112 0.053232  =112/2104\n#> Yes      62 222 0.218310    =62/284\n#> Totals 2054 334 0.072864  =174/2388\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.236582    0.718447 202\n#> 2                       max f2  0.100378    0.797057 267\n#> 3                 max f0point5  0.364699    0.725076 161\n#> 4                 max accuracy  0.364699    0.932998 161\n#> 5                max precision  0.947366    0.909091   7\n#> 6                   max recall  0.005218    1.000000 386\n#> 7              max specificity  0.983762    0.999525   0\n#> 8             max absolute_mcc  0.236582    0.679850 202\n#> 9   max min_per_class_accuracy  0.115178    0.897887 258\n#> 10 max mean_per_class_accuracy  0.100378    0.901900 267\n#> 11                     max tns  0.983762 2103.000000   0\n#> 12                     max fns  0.983762  284.000000   0\n#> 13                     max fps  0.001382 2104.000000 399\n#> 14                     max tps  0.005218  284.000000 386\n#> 15                     max tnr  0.983762    0.999525   0\n#> 16                     max fnr  0.983762    1.000000   0\n#> 17                     max fpr  0.001382    1.000000 399\n#> 18                     max tpr  0.005218    1.000000 386\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05202655\n#> RMSE:  0.2280933\n#> LogLoss:  0.1747359\n#> Mean Per-Class Error:  0.1583055\n#> AUC:  0.9501769\n#> AUCPR:  0.7306402\n#> Gini:  0.9003539\n#> R^2:  0.5024292\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error         Rate\n#> No     11585  584 0.047991   =584/12169\n#> Yes      440 1198 0.268620    =440/1638\n#> Totals 12025 1782 0.074165  =1024/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.317314     0.700585 212\n#> 2                       max f2  0.103294     0.774768 296\n#> 3                 max f0point5  0.570225     0.720026 133\n#> 4                 max accuracy  0.450369     0.929891 169\n#> 5                max precision  0.990661     1.000000   0\n#> 6                   max recall  0.006345     1.000000 386\n#> 7              max specificity  0.990661     1.000000   0\n#> 8             max absolute_mcc  0.207829     0.660075 251\n#> 9   max min_per_class_accuracy  0.103294     0.887057 296\n#> 10 max mean_per_class_accuracy  0.099612     0.887244 298\n#> 11                     max tns  0.990661 12169.000000   0\n#> 12                     max fns  0.990661  1637.000000   0\n#> 13                     max fps  0.001275 12169.000000 399\n#> 14                     max tps  0.006345  1638.000000 386\n#> 15                     max tnr  0.990661     1.000000   0\n#> 16                     max fnr  0.990661     0.999389   0\n#> 17                     max fpr  0.001275     1.000000 399\n#> 18                     max tpr  0.006345     1.000000 386\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                               mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> accuracy                  0.922647  0.007915   0.926141   0.931933   0.910540\n#> auc                       0.949398  0.008029   0.960020   0.954273   0.948030\n#> err                       0.077353  0.007915   0.073860   0.068067   0.089460\n#> err_count               213.600000 21.824299 204.000000 188.000000 247.000000\n#> f0point5                  0.667315  0.031318   0.704633   0.685048   0.621275\n#> f1                        0.706768  0.024213   0.741117   0.719403   0.686945\n#> f2                        0.752057  0.027827   0.781585   0.757385   0.768141\n#> lift_top_group            7.125719  0.652002   6.576191   8.032806   7.281758\n#> logloss                   0.175282  0.010640   0.168906   0.159526   0.183315\n#> max_per_class_error       0.213696  0.040250   0.188889   0.214984   0.166154\n#> mcc                       0.667927  0.025474   0.701972   0.684075   0.650381\n#> mean_per_class_accuracy   0.863605  0.016771   0.877246   0.867661   0.877309\n#> mean_per_class_error      0.136395  0.016771   0.122754   0.132339   0.122691\n#> mse                       0.052119  0.003499   0.050890   0.046815   0.055686\n#> pr_auc                    0.729275  0.037288   0.784088   0.751528   0.699162\n#> precision                 0.643656  0.036946   0.682243   0.663912   0.584052\n#> r2                        0.500647  0.037141   0.551048   0.526150   0.463813\n#> recall                    0.786304  0.040250   0.811111   0.785016   0.833846\n#> rmse                      0.228190  0.007739   0.225587   0.216367   0.235978\n#> specificity               0.940906  0.011587   0.943381   0.950306   0.920772\n#>                         cv_4_valid cv_5_valid\n#> accuracy                  0.923941   0.920681\n#> auc                       0.939202   0.945467\n#> err                       0.076059   0.079319\n#> err_count               210.000000 219.000000\n#> f0point5                  0.668092   0.657527\n#> f1                        0.704225   0.682148\n#> f2                        0.744491   0.708685\n#> lift_top_group            7.326847   6.410991\n#> logloss                   0.182397   0.182268\n#> max_per_class_error       0.226006   0.272446\n#> mcc                       0.664547   0.638660\n#> mean_per_class_accuracy   0.858900   0.836911\n#> mean_per_class_error      0.141100   0.163089\n#> mse                       0.052551   0.054653\n#> pr_auc                    0.710933   0.700662\n#> precision                 0.645995   0.642077\n#> r2                        0.491285   0.470938\n#> recall                    0.773994   0.727554\n#> rmse                      0.229239   0.233779\n#> specificity               0.943806   0.946267\n\nsource(\"extract_h2o_model_name_by_position.R\")\n\nmodel <- automl_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(6) %>% \n  h2o.getModel()\n\n#> GBM_3_AutoML_5_20230530_175439\n\nmodel\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: gbm\n#> Model ID:  GBM_3_AutoML_5_20230530_175439 \n#> Model Summary: \n#>   number_of_trees number_of_internal_trees model_size_in_bytes min_depth\n#> 1              75                       75               79408         8\n#>   max_depth mean_depth min_leaves max_leaves mean_leaves\n#> 1         8    8.00000         38        140    79.46667\n#> \n#> \n#> H2OBinomialMetrics: gbm\n#> ** Reported on training data. **\n#> \n#> MSE:  0.03227019\n#> RMSE:  0.1796391\n#> LogLoss:  0.1178047\n#> Mean Per-Class Error:  0.09189692\n#> AUC:  0.9831668\n#> AUCPR:  0.9116702\n#> Gini:  0.9663335\n#> R^2:  0.6913748\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error        Rate\n#> No     11864  305 0.025064  =305/12169\n#> Yes      260 1378 0.158730   =260/1638\n#> Totals 12124 1683 0.040921  =565/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.362588     0.829871 191\n#> 2                       max f2  0.209274     0.859429 243\n#> 3                 max f0point5  0.571826     0.867204 128\n#> 4                 max accuracy  0.418468     0.960672 174\n#> 5                max precision  0.988394     1.000000   0\n#> 6                   max recall  0.021550     1.000000 361\n#> 7              max specificity  0.988394     1.000000   0\n#> 8             max absolute_mcc  0.418468     0.807813 174\n#> 9   max min_per_class_accuracy  0.183491     0.931013 255\n#> 10 max mean_per_class_accuracy  0.187581     0.931674 253\n#> 11                     max tns  0.988394 12169.000000   0\n#> 12                     max fns  0.988394  1633.000000   0\n#> 13                     max fps  0.001207 12169.000000 399\n#> 14                     max tps  0.021550  1638.000000 361\n#> 15                     max tnr  0.988394     1.000000   0\n#> 16                     max fnr  0.988394     0.996947   0\n#> 17                     max fpr  0.001207     1.000000 399\n#> 18                     max tpr  0.021550     1.000000 361\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.05029949\n#> RMSE:  0.2242755\n#> LogLoss:  0.1694448\n#> Mean Per-Class Error:  0.153333\n#> AUC:  0.9525987\n#> AUCPR:  0.7577052\n#> Gini:  0.9051973\n#> R^2:  0.5199702\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     2007  97 0.046103   =97/2104\n#> Yes      74 210 0.260563    =74/284\n#> Totals 2081 307 0.071608  =171/2388\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.304765    0.710660 185\n#> 2                       max f2  0.135394    0.794393 255\n#> 3                 max f0point5  0.399969    0.731424 156\n#> 4                 max accuracy  0.399969    0.933836 156\n#> 5                max precision  0.984816    1.000000   0\n#> 6                   max recall  0.005322    1.000000 387\n#> 7              max specificity  0.984816    1.000000   0\n#> 8             max absolute_mcc  0.349545    0.671298 172\n#> 9   max min_per_class_accuracy  0.135394    0.897887 255\n#> 10 max mean_per_class_accuracy  0.122125    0.898952 262\n#> 11                     max tns  0.984816 2104.000000   0\n#> 12                     max fns  0.984816  283.000000   0\n#> 13                     max fps  0.001194 2104.000000 399\n#> 14                     max tps  0.005322  284.000000 387\n#> 15                     max tnr  0.984816    1.000000   0\n#> 16                     max fnr  0.984816    0.996479   0\n#> 17                     max fpr  0.001194    1.000000 399\n#> 18                     max tpr  0.005322    1.000000 387\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: gbm\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.05200347\n#> RMSE:  0.2280427\n#> LogLoss:  0.1747426\n#> Mean Per-Class Error:  0.1482556\n#> AUC:  0.949727\n#> AUCPR:  0.7304455\n#> Gini:  0.899454\n#> R^2:  0.5026499\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error         Rate\n#> No     11525  644 0.052921   =644/12169\n#> Yes      399 1239 0.243590    =399/1638\n#> Totals 11924 1883 0.075541  =1043/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.305434     0.703777 213\n#> 2                       max f2  0.123195     0.774443 282\n#> 3                 max f0point5  0.533390     0.722410 140\n#> 4                 max accuracy  0.527209     0.929529 142\n#> 5                max precision  0.966924     0.906250   5\n#> 6                   max recall  0.005931     1.000000 387\n#> 7              max specificity  0.989873     0.999918   0\n#> 8             max absolute_mcc  0.278764     0.663005 221\n#> 9   max min_per_class_accuracy  0.109985     0.883474 289\n#> 10 max mean_per_class_accuracy  0.120163     0.886035 284\n#> 11                     max tns  0.989873 12168.000000   0\n#> 12                     max fns  0.989873  1637.000000   0\n#> 13                     max fps  0.001146 12169.000000 399\n#> 14                     max tps  0.005931  1638.000000 387\n#> 15                     max tnr  0.989873     0.999918   0\n#> 16                     max fnr  0.989873     0.999389   0\n#> 17                     max fpr  0.001146     1.000000 399\n#> 18                     max tpr  0.005931     1.000000 387\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                               mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> accuracy                  0.926848  0.005727   0.927589   0.931933   0.917421\n#> auc                       0.949199  0.005360   0.958190   0.949558   0.946437\n#> err                       0.073152  0.005727   0.072411   0.068067   0.082579\n#> err_count               202.000000 15.795569 200.000000 188.000000 228.000000\n#> f0point5                  0.685256  0.024456   0.710784   0.689445   0.646022\n#> f1                        0.709516  0.023695   0.743590   0.706250   0.679775\n#> f2                        0.735753  0.026207   0.779570   0.723895   0.717250\n#> lift_top_group            7.424373  0.610397   6.850198   8.032806   7.585165\n#> logloss                   0.175109  0.006994   0.168463   0.167852   0.184153\n#> max_per_class_error       0.245521  0.030044   0.194444   0.263844   0.255385\n#> mcc                       0.669544  0.025493   0.704548   0.668535   0.635965\n#> mean_per_class_accuracy   0.852165  0.014155   0.875717   0.846286   0.842546\n#> mean_per_class_error      0.147835  0.014155   0.124283   0.153714   0.157454\n#> mse                       0.052086  0.002728   0.049852   0.049797   0.056001\n#> pr_auc                    0.729292  0.036566   0.785022   0.730898   0.698756\n#> precision                 0.670065  0.026114   0.690476   0.678679   0.625323\n#> r2                        0.500522  0.037610   0.560197   0.495967   0.460782\n#> recall                    0.754479  0.030044   0.805556   0.736156   0.744615\n#> rmse                      0.228162  0.005941   0.223277   0.223152   0.236644\n#> specificity               0.949850  0.006540   0.945878   0.956415   0.940476\n#>                         cv_4_valid cv_5_valid\n#> accuracy                  0.930822   0.926476\n#> auc                       0.944382   0.947427\n#> err                       0.069178   0.073524\n#> err_count               191.000000 203.000000\n#> f0point5                  0.698340   0.681687\n#> f1                        0.718704   0.699259\n#> f2                        0.740291   0.717762\n#> lift_top_group            7.937417   6.716276\n#> logloss                   0.175920   0.179156\n#> max_per_class_error       0.244582   0.269350\n#> mcc                       0.680417   0.658254\n#> mean_per_class_accuracy   0.854739   0.841535\n#> mean_per_class_error      0.145261   0.158465\n#> mse                       0.050969   0.053812\n#> pr_auc                    0.737665   0.694118\n#> precision                 0.685393   0.670455\n#> r2                        0.506591   0.479074\n#> recall                    0.755418   0.730650\n#> rmse                      0.225764   0.231974\n#> specificity               0.954061   0.952420"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#predictions",
    "href": "content/01_journal/Challenge5/Challenge5.html#predictions",
    "title": "Challenge5",
    "section": "\n10.6 5. Predictions",
    "text": "10.6 5. Predictions\n\npredictions <- h2o.predict(model, newdata = as.h2o(test_tbl))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\npredictions_tbl <- predictions%>% as_tibble()"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#save-the-leader-model",
    "href": "content/01_journal/Challenge5/Challenge5.html#save-the-leader-model",
    "title": "Challenge5",
    "section": "\n10.7 6. Save the leader model",
    "text": "10.7 6. Save the leader model\n\nmodel %>% h2o.saveModel(path = \"05_Modeling/h20_models/\")\n\n#> [1] \"C:\\\\Users\\\\tiend\\\\Documents\\\\GitHub\\\\ss23-bdml-tiend96\\\\content\\\\01_journal\\\\Challenge5\\\\05_Modeling\\\\h20_models\\\\GBM_3_AutoML_5_20230530_175439\""
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#leaderboard-visualization",
    "href": "content/01_journal/Challenge5/Challenge5.html#leaderboard-visualization",
    "title": "Challenge5",
    "section": "\n10.8 1. Leaderboard Visualization",
    "text": "10.8 1. Leaderboard Visualization\n\ndata_transformed_tbl <- automl_models_h2o@leaderboard %>%\n        as_tibble() %>%\n        select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n        mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n        slice(1:15) %>% \n        rownames_to_column(var = \"rowname\") %>%\n        # Visually this step will not change anything\n        # It reorders the factors under the hood\n        mutate(\n          model_id   = as_factor(model_id) %>% reorder(auc),\n          model_type = as.factor(model_type)\n          ) %>% \n          pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       ) %>% \n        mutate(model_id = paste0(rowname, \". \", model_id) %>% as_factor() %>% fct_rev())\n\n\ndata_transformed_tbl %>%\n        ggplot(aes(value, model_id, color = model_type)) +\n        geom_point(size = 3) +\n        geom_label(aes(label = round(value, 2), hjust = \"inward\")) +\n        \n        # Facet to break out logloss and auc\n        facet_wrap(~ key, scales = \"free_x\") +\n        labs(title = \"Leaderboard Metrics\",\n             subtitle = paste0(\"Ordered by: \", \"auc\"),\n             y = \"Model Postion, Model ID\", x = \"\") + \n        theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#tune-a-model-with-grid-search",
    "href": "content/01_journal/Challenge5/Challenge5.html#tune-a-model-with-grid-search",
    "title": "Challenge5",
    "section": "\n10.9 2. Tune a model with grid search",
    "text": "10.9 2. Tune a model with grid search\n\n#h2o.getModel(\"DeepLearning_1_AutoML_2_20230526_203055\") %>% \n#  h2o.saveModel(path = \"05_Modeling/h20_models/\")\n\n#h2o.getModel(\"StackedEnsemble_AllModels_1_AutoML_2_20230526_203055\") %>% \n#  h2o.saveModel(path = \"05_Modeling/h20_models/\")\n\n\ndeeplearning_h2o <- h2o.loadModel(\"05_Modeling/h20_models/DeepLearning_1_AutoML_2_20230526_203055\")\n\ndeeplearning_h2o\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: deeplearning\n#> Model ID:  DeepLearning_1_AutoML_2_20230526_203055 \n#> Status of Neuron Layers: predicting went_on_backorder, 2-class classification, bernoulli distribution, CrossEntropy loss, 592 weights/biases, 15,6 KB, 157.449 training samples, mini-batch size 1\n#>   layer units      type dropout       l1       l2 mean_rate rate_rms momentum\n#> 1     1    34     Input  0.00 %       NA       NA        NA       NA       NA\n#> 2     2    10 Rectifier  0.00 % 0.000000 0.000000  0.184841 0.389585 0.000000\n#> 3     3    10 Rectifier  0.00 % 0.000000 0.000000  0.005024 0.011562 0.000000\n#> 4     4    10 Rectifier  0.00 % 0.000000 0.000000  0.005415 0.007296 0.000000\n#> 5     5     2   Softmax      NA 0.000000 0.000000  0.003258 0.003434 0.000000\n#>   mean_weight weight_rms mean_bias bias_rms\n#> 1          NA         NA        NA       NA\n#> 2   -0.032570   0.421491  0.396073 0.096704\n#> 3   -0.004891   0.376070  0.954589 0.160953\n#> 4   -0.034898   0.358855  0.943122 0.047012\n#> 5   -0.197805   1.309651 -0.017211 0.006698\n#> \n#> \n#> H2OBinomialMetrics: deeplearning\n#> ** Reported on training data. **\n#> ** Metrics reported on temporary training frame with 10069 samples **\n#> \n#> MSE:  0.08463664\n#> RMSE:  0.2909238\n#> LogLoss:  0.2843011\n#> Mean Per-Class Error:  0.2468229\n#> AUC:  0.8411112\n#> AUCPR:  0.4170013\n#> Gini:  0.6822223\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No  Yes    Error         Rate\n#> No     7507 1391 0.156327   =1391/8898\n#> Yes     395  776 0.337319    =395/1171\n#> Totals 7902 2167 0.177376  =1786/10069\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.228451    0.464949 193\n#> 2                       max f2  0.211372    0.584502 210\n#> 3                 max f0point5  0.366601    0.449608 115\n#> 4                 max accuracy  0.437428    0.890357  84\n#> 5                max precision  0.879024    1.000000   0\n#> 6                   max recall  0.000524    1.000000 398\n#> 7              max specificity  0.879024    1.000000   0\n#> 8             max absolute_mcc  0.225789    0.395894 196\n#> 9   max min_per_class_accuracy  0.205202    0.760034 215\n#> 10 max mean_per_class_accuracy  0.211372    0.765386 210\n#> 11                     max tns  0.879024 8898.000000   0\n#> 12                     max fns  0.879024 1170.000000   0\n#> 13                     max fps  0.000122 8898.000000 399\n#> 14                     max tps  0.000524 1171.000000 398\n#> 15                     max tnr  0.879024    1.000000   0\n#> 16                     max fnr  0.879024    0.999146   0\n#> 17                     max fpr  0.000122    1.000000 399\n#> 18                     max tpr  0.000524    1.000000 398\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: deeplearning\n#> ** Reported on validation data. **\n#> ** Metrics reported on full validation frame **\n#> \n#> MSE:  0.0866388\n#> RMSE:  0.2943447\n#> LogLoss:  0.2977592\n#> Mean Per-Class Error:  0.2528149\n#> AUC:  0.81758\n#> AUCPR:  0.4314019\n#> Gini:  0.6351601\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     1781 323 0.153517  =323/2104\n#> Yes     100 184 0.352113   =100/284\n#> Totals 1881 507 0.177136  =423/2388\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.227982    0.465234 173\n#> 2                       max f2  0.215623    0.580535 187\n#> 3                 max f0point5  0.364793    0.490088  90\n#> 4                 max accuracy  0.404363    0.891960  74\n#> 5                max precision  0.771092    0.916667   8\n#> 6                   max recall  0.000362    1.000000 398\n#> 7              max specificity  0.882022    0.999525   0\n#> 8             max absolute_mcc  0.227982    0.391324 173\n#> 9   max min_per_class_accuracy  0.203335    0.742958 200\n#> 10 max mean_per_class_accuracy  0.215623    0.760058 187\n#> 11                     max tns  0.882022 2103.000000   0\n#> 12                     max fns  0.882022  284.000000   0\n#> 13                     max fps  0.000076 2104.000000 399\n#> 14                     max tps  0.000362  284.000000 398\n#> 15                     max tnr  0.882022    0.999525   0\n#> 16                     max fnr  0.882022    1.000000   0\n#> 17                     max fpr  0.000076    1.000000 399\n#> 18                     max tpr  0.000362    1.000000 398\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: deeplearning\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.08792789\n#> RMSE:  0.2965264\n#> LogLoss:  0.2919592\n#> Mean Per-Class Error:  0.3054919\n#> AUC:  0.8182865\n#> AUCPR:  0.391059\n#> Gini:  0.6365729\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>           No  Yes    Error         Rate\n#> No     10707 1462 0.120141  =1462/12169\n#> Yes      804  834 0.490842    =804/1638\n#> Totals 11511 2296 0.164120  =2266/13807\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold        value idx\n#> 1                       max f1  0.191383     0.423996 194\n#> 2                       max f2  0.113368     0.561419 270\n#> 3                 max f0point5  0.266353     0.435993 141\n#> 4                 max accuracy  0.330904     0.886579 111\n#> 5                max precision  0.907997     1.000000   0\n#> 6                   max recall  0.002397     1.000000 395\n#> 7              max specificity  0.907997     1.000000   0\n#> 8             max absolute_mcc  0.164009     0.340605 220\n#> 9   max min_per_class_accuracy  0.142871     0.734325 240\n#> 10 max mean_per_class_accuracy  0.113368     0.742114 270\n#> 11                     max tns  0.907997 12169.000000   0\n#> 12                     max fns  0.907997  1637.000000   0\n#> 13                     max fps  0.000103 12169.000000 399\n#> 14                     max tps  0.002397  1638.000000 395\n#> 15                     max tnr  0.907997     1.000000   0\n#> 16                     max fnr  0.907997     0.999389   0\n#> 17                     max fpr  0.000103     1.000000 399\n#> 18                     max tpr  0.002397     1.000000 395\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                               mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> accuracy                  0.806331  0.035125   0.828385   0.776249   0.760956\n#> auc                       0.819928  0.022356   0.854677   0.796389   0.805157\n#> err                       0.193669  0.035125   0.171615   0.223751   0.239044\n#> err_count               534.800000 97.001030 474.000000 618.000000 660.000000\n#> f0point5                  0.371767  0.052307   0.436391   0.310982   0.330122\n#> f1                        0.435921  0.045205   0.498943   0.383234   0.413854\n#> f2                        0.530549  0.040372   0.582428   0.499220   0.554498\n#> lift_top_group            5.596924  1.313678   5.754167   5.462308   3.640879\n#> logloss                   0.291959  0.007172   0.289661   0.291884   0.303956\n#> max_per_class_error       0.374417  0.067654   0.344444   0.374593   0.283077\n#> mcc                       0.357968  0.045223   0.419852   0.304592   0.343527\n#> mean_per_class_accuracy   0.728123  0.022278   0.754922   0.710260   0.741877\n#> mean_per_class_error      0.271877  0.022278   0.245078   0.289740   0.258123\n#> mse                       0.087928  0.002728   0.089145   0.087093   0.091961\n#> pr_auc                    0.396021  0.073451   0.490232   0.317965   0.325204\n#> precision                 0.339053  0.054654   0.402730   0.276259   0.290886\n#> r2                        0.157384  0.041778   0.213553   0.118466   0.114527\n#> recall                    0.625583  0.067654   0.655556   0.625407   0.716923\n#> rmse                      0.296498  0.004585   0.298572   0.295115   0.303250\n#> specificity               0.830662  0.046840   0.854288   0.795112   0.766831\n#>                         cv_4_valid cv_5_valid\n#> accuracy                  0.838464   0.827599\n#> auc                       0.824263   0.819151\n#> err                       0.161536   0.172401\n#> err_count               446.000000 476.000000\n#> f0point5                  0.408337   0.373006\n#> f1                        0.462651   0.420925\n#> f2                        0.533630   0.482970\n#> lift_top_group            7.326847   5.800420\n#> logloss                   0.284885   0.289410\n#> max_per_class_error       0.405573   0.464396\n#> mcc                       0.386188   0.335680\n#> mean_per_class_accuracy   0.732611   0.700944\n#> mean_per_class_error      0.267389   0.299056\n#> mse                       0.084833   0.086607\n#> pr_auc                    0.430515   0.416189\n#> precision                 0.378698   0.346693\n#> r2                        0.178773   0.161600\n#> recall                    0.594427   0.535604\n#> rmse                      0.291262   0.294291\n#> specificity               0.870796   0.866284\n\ntest_tbl\n\n\n\n  \n\n\nh2o.performance(deeplearning_h2o, newdata = as.h2o(test_tbl))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\n#> H2OBinomialMetrics: deeplearning\n#> \n#> MSE:  0.09187445\n#> RMSE:  0.303108\n#> LogLoss:  0.3106403\n#> Mean Per-Class Error:  0.2567725\n#> AUC:  0.8081124\n#> AUCPR:  0.3648183\n#> Gini:  0.6162247\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>          No Yes    Error       Rate\n#> No     2078 436 0.173429  =436/2514\n#> Yes     117 227 0.340116   =117/344\n#> Totals 2195 663 0.193492  =553/2858\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.223398    0.450844 187\n#> 2                       max f2  0.222129    0.558809 188\n#> 3                 max f0point5  0.372856    0.448718  96\n#> 4                 max accuracy  0.381639    0.884535  90\n#> 5                max precision  0.855815    1.000000   0\n#> 6                   max recall  0.000111    1.000000 399\n#> 7              max specificity  0.855815    1.000000   0\n#> 8             max absolute_mcc  0.222129    0.375072 188\n#> 9   max min_per_class_accuracy  0.197537    0.737470 212\n#> 10 max mean_per_class_accuracy  0.222129    0.744543 188\n#> 11                     max tns  0.855815 2514.000000   0\n#> 12                     max fns  0.855815  343.000000   0\n#> 13                     max fps  0.000111 2514.000000 399\n#> 14                     max tps  0.000111  344.000000 399\n#> 15                     max tnr  0.855815    1.000000   0\n#> 16                     max fnr  0.855815    0.997093   0\n#> 17                     max fpr  0.000111    1.000000 399\n#> 18                     max tpr  0.000111    1.000000 399\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n\n\n\ndeeplearning_grid_01 <- h2o.grid(\n\n    # See help page for available algos\n    algorithm = \"deeplearning\",\n    \n    # I just use the same as the object\n    grid_id = \"deeplearning_grid_01\",\n    \n    # The following is for ?h2o.deeplearning()\n    # predictor and response variables\n    x = x,\n    y = y,\n    \n    # training and validation frame and crossfold validation\n    training_frame   = train_h2o,\n    validation_frame = valid_h2o,\n    nfolds = 5,\n    \n    # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n    hyper_params = list(\n        # Use some combinations (the first one was the original)\n        hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n        epochs = c(10, 50, 100)\n    )\n)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\ndeeplearning_grid_01\n\n#> H2O Grid Details\n#> ================\n#> \n#> Grid ID: deeplearning_grid_01 \n#> Used hyper parameters: \n#>   -  epochs \n#>   -  hidden \n#> Number of models: 45 \n#> Number of failed models: 0 \n#> \n#> Hyper-Parameter Search Summary: ordered by increasing logloss\n#>      epochs       hidden                     model_ids logloss\n#> 1  51.98619 [50, 20, 10] deeplearning_grid_01_model_41 0.24401\n#> 2 101.38806 [10, 10, 10] deeplearning_grid_01_model_21 0.24401\n#> 3  51.99596 [10, 10, 10] deeplearning_grid_01_model_38 0.24427\n#> 4 101.39909 [20, 20, 20] deeplearning_grid_01_model_45 0.24590\n#> 5 101.42416 [20, 20, 20] deeplearning_grid_01_model_27 0.25220\n#> \n#> ---\n#>       epochs       hidden                     model_ids logloss\n#> 40  52.03909 [20, 20, 20] deeplearning_grid_01_model_35 0.40105\n#> 41  10.42099 [50, 20, 10] deeplearning_grid_01_model_13 0.40287\n#> 42 104.05887 [50, 20, 10] deeplearning_grid_01_model_15 0.42832\n#> 43 104.06317 [20, 20, 20] deeplearning_grid_01_model_18 0.43517\n#> 44 103.95825 [50, 20, 10]  deeplearning_grid_01_model_6 0.45414\n#> 45 103.98630 [50, 20, 10] deeplearning_grid_01_model_33 0.46758\n\nh2o.getGrid(grid_id = \"deeplearning_grid_01\", sort_by = \"auc\", decreasing = TRUE)\n\n#> H2O Grid Details\n#> ================\n#> \n#> Grid ID: deeplearning_grid_01 \n#> Used hyper parameters: \n#>   -  epochs \n#>   -  hidden \n#> Number of models: 45 \n#> Number of failed models: 0 \n#> \n#> Hyper-Parameter Search Summary: ordered by decreasing auc\n#>      epochs       hidden                     model_ids     auc\n#> 1 101.38806 [10, 10, 10] deeplearning_grid_01_model_21 0.89950\n#> 2  51.99596 [10, 10, 10] deeplearning_grid_01_model_38 0.89682\n#> 3 101.42416 [20, 20, 20] deeplearning_grid_01_model_27 0.89442\n#> 4 101.39909 [20, 20, 20] deeplearning_grid_01_model_45 0.89384\n#> 5 101.39731 [50, 20, 10] deeplearning_grid_01_model_24 0.89307\n#> \n#> ---\n#>       epochs       hidden                     model_ids     auc\n#> 40 104.07222 [20, 20, 20] deeplearning_grid_01_model_36 0.77415\n#> 41  52.04538 [20, 20, 20]  deeplearning_grid_01_model_8 0.77149\n#> 42 103.95825 [50, 20, 10]  deeplearning_grid_01_model_6 0.76178\n#> 43 104.06317 [20, 20, 20] deeplearning_grid_01_model_18 0.75614\n#> 44  52.03909 [20, 20, 20] deeplearning_grid_01_model_35 0.73630\n#> 45  52.65658 [10, 10, 10]  deeplearning_grid_01_model_2 0.70864\n\n\n\ndeeplearning_grid_01_model_1 <- h2o.getModel(\"deeplearning_grid_01_model_1\")\n\ndeeplearning_grid_01_model_1 %>% h2o.auc(train = T, valid = T, xval = T)\n\n#>     train     valid      xval \n#> 0.9336385 0.8394200 0.8044856\n\n##     train     valid      xval \n## 0.9093134 0.7922078 0.8299115 \n\n# We can tell the model is overfitting because of the huge difference between training AUC and the validation / cross validation AUC\n\n# Run it on the test data\ndeeplearning_grid_01_model_1 %>%\n    h2o.performance(newdata = as.h2o(test_tbl))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> [1] \"WARNING: Model metrics cannot be calculated and metric_json is empty due to the absence of the response column in your dataset.\"\n\n\n#> NULL"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#visualize-the-trade-of-between-the-precision-and-the-recall-and-the-optimal-threshold",
    "href": "content/01_journal/Challenge5/Challenge5.html#visualize-the-trade-of-between-the-precision-and-the-recall-and-the-optimal-threshold",
    "title": "Challenge5",
    "section": "\n10.10 3 Visualize the trade of between the precision and the recall and the optimal threshold",
    "text": "10.10 3 Visualize the trade of between the precision and the recall and the optimal threshold"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#h2o-performance",
    "href": "content/01_journal/Challenge5/Challenge5.html#h2o-performance",
    "title": "Challenge5",
    "section": "\n10.11 H2o Performance",
    "text": "10.11 H2o Performance\n\nstacked_ensemble_h2o <- h2o.loadModel(\"05_Modeling/h20_models/StackedEnsemble_AllModels_1_AutoML_2_20230526_203055\")\ndeeplearning_h2o     <- h2o.loadModel(\"05_Modeling/h20_models/DeepLearning_1_AutoML_2_20230526_203055\")\nglm_h2o              <- h2o.loadModel(\"05_Modeling/h20_models/GBM_2_AutoML_2_20230526_203055\")"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#create-a-performance-object",
    "href": "content/01_journal/Challenge5/Challenge5.html#create-a-performance-object",
    "title": "Challenge5",
    "section": "\n10.12 Create a Performance Object",
    "text": "10.12 Create a Performance Object\n\nperformance_h2o <- h2o.performance(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\ntypeof(performance_h2o)\n\n#> [1] \"S4\"\n\nperformance_h2o %>% slotNames()\n\n#> [1] \"algorithm\" \"on_train\"  \"on_valid\"  \"on_xval\"   \"metrics\"\n\n# We are focusing on the slot metrics. This slot contains all possible metrics\nperformance_h2o@metrics\n\n#> $model\n#> $model$`__meta`\n#> $model$`__meta`$schema_version\n#> [1] 3\n#> \n#> $model$`__meta`$schema_name\n#> [1] \"ModelKeyV3\"\n#> \n#> $model$`__meta`$schema_type\n#> [1] \"Key<Model>\"\n#> \n#> \n#> $model$name\n#> [1] \"StackedEnsemble_AllModels_1_AutoML_2_20230526_203055\"\n#> \n#> $model$type\n#> [1] \"Key<Model>\"\n#> \n#> $model$URL\n#> [1] \"/3/Models/StackedEnsemble_AllModels_1_AutoML_2_20230526_203055\"\n#> \n#> \n#> $model_checksum\n#> [1] \"7402300823581001072\"\n#> \n#> $frame\n#> $frame$name\n#> [1] \"test_tbl_sid_a122_421\"\n#> \n#> \n#> $frame_checksum\n#> [1] 0\n#> \n#> $description\n#> NULL\n#> \n#> $scoring_time\n#> [1] 1.685126e+12\n#> \n#> $predictions\n#> NULL\n#> \n#> $MSE\n#> [1] 0.05318809\n#> \n#> $RMSE\n#> [1] 0.2306254\n#> \n#> $nobs\n#> [1] 2858\n#> \n#> $custom_metric_name\n#> NULL\n#> \n#> $custom_metric_value\n#> [1] 0\n#> \n#> $r2\n#> [1] 0.4976399\n#> \n#> $logloss\n#> [1] 0.1756038\n#> \n#> $AUC\n#> [1] 0.9497442\n#> \n#> $pr_auc\n#> [1] 0.742566\n#> \n#> $Gini\n#> [1] 0.8994884\n#> \n#> $mean_per_class_error\n#> [1] 0.159775\n#> \n#> $domain\n#> [1] \"No\"  \"Yes\"\n#> \n#> $cm\n#> $cm$`__meta`\n#> $cm$`__meta`$schema_version\n#> [1] 3\n#> \n#> $cm$`__meta`$schema_name\n#> [1] \"ConfusionMatrixV3\"\n#> \n#> $cm$`__meta`$schema_type\n#> [1] \"ConfusionMatrix\"\n#> \n#> \n#> $cm$table\n#> Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n#>          No Yes  Error          Rate\n#> No     2383 131 0.0521 = 131 / 2.514\n#> Yes      92 252 0.2674 =    92 / 344\n#> Totals 2475 383 0.0780 = 223 / 2.858\n#> \n#> \n#> $thresholds_and_metric_scores\n#> Metrics for Thresholds: Binomial metrics as a function of classification thresholds\n#>   threshold       f1       f2 f0point5 accuracy precision   recall specificity\n#> 1  0.971388 0.005797 0.003631 0.014368 0.879986  1.000000 0.002907    1.000000\n#> 2  0.965911 0.011561 0.007257 0.028409 0.880336  1.000000 0.005814    1.000000\n#> 3  0.961461 0.022989 0.014493 0.055556 0.881036  1.000000 0.011628    1.000000\n#> 4  0.950628 0.034286 0.021708 0.081522 0.881735  1.000000 0.017442    1.000000\n#> 5  0.947078 0.045455 0.028902 0.106383 0.882435  1.000000 0.023256    1.000000\n#>   absolute_mcc min_per_class_accuracy mean_per_class_accuracy  tns fns fps tps\n#> 1     0.050576               0.002907                0.501453 2514 343   0   1\n#> 2     0.071538               0.005814                0.502907 2514 342   0   2\n#> 3     0.101206               0.011628                0.505814 2514 340   0   4\n#> 4     0.123995               0.017442                0.508721 2514 338   0   6\n#> 5     0.143227               0.023256                0.511628 2514 336   0   8\n#>        tnr      fnr      fpr      tpr idx\n#> 1 1.000000 0.997093 0.000000 0.002907   0\n#> 2 1.000000 0.994186 0.000000 0.005814   1\n#> 3 1.000000 0.988372 0.000000 0.011628   2\n#> 4 1.000000 0.982558 0.000000 0.017442   3\n#> 5 1.000000 0.976744 0.000000 0.023256   4\n#> \n#> ---\n#>     threshold       f1       f2 f0point5 accuracy precision   recall\n#> 395  0.001305 0.232905 0.431510 0.159496 0.207138  0.131801 1.000000\n#> 396  0.001151 0.232432 0.430862 0.159141 0.205038  0.131498 1.000000\n#> 397  0.000985 0.227288 0.423750 0.155291 0.181596  0.128215 1.000000\n#> 398  0.000717 0.222294 0.416768 0.151569 0.157803  0.125045 1.000000\n#> 399  0.000501 0.217172 0.409524 0.147766 0.132260  0.121813 1.000000\n#> 400  0.000141 0.214866 0.406235 0.146060 0.120364  0.120364 1.000000\n#>     specificity absolute_mcc min_per_class_accuracy mean_per_class_accuracy tns\n#> 395    0.098648     0.114026               0.098648                0.549324 248\n#> 396    0.096261     0.112509               0.096261                0.548130 242\n#> 397    0.069610     0.094472               0.069610                0.534805 175\n#> 398    0.042562     0.072953               0.042562                0.521281 107\n#> 399    0.013524     0.040589               0.013524                0.506762  34\n#> 400    0.000000     0.000000               0.000000                0.500000   0\n#>     fns  fps tps      tnr      fnr      fpr      tpr idx\n#> 395   0 2266 344 0.098648 0.000000 0.901352 1.000000 394\n#> 396   0 2272 344 0.096261 0.000000 0.903739 1.000000 395\n#> 397   0 2339 344 0.069610 0.000000 0.930390 1.000000 396\n#> 398   0 2407 344 0.042562 0.000000 0.957438 1.000000 397\n#> 399   0 2480 344 0.013524 0.000000 0.986476 1.000000 398\n#> 400   0 2514 344 0.000000 0.000000 1.000000 1.000000 399\n#> \n#> $max_criteria_and_metric_scores\n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold       value idx\n#> 1                       max f1  0.329130    0.693260 197\n#> 2                       max f2  0.129161    0.776173 272\n#> 3                 max f0point5  0.719155    0.714286  88\n#> 4                 max accuracy  0.486666    0.927922 149\n#> 5                max precision  0.971388    1.000000   0\n#> 6                   max recall  0.003402    1.000000 386\n#> 7              max specificity  0.971388    1.000000   0\n#> 8             max absolute_mcc  0.329130    0.649937 197\n#> 9   max min_per_class_accuracy  0.110797    0.883721 281\n#> 10 max mean_per_class_accuracy  0.090924    0.887519 293\n#> 11                     max tns  0.971388 2514.000000   0\n#> 12                     max fns  0.971388  343.000000   0\n#> 13                     max fps  0.000141 2514.000000 399\n#> 14                     max tps  0.003402  344.000000 386\n#> 15                     max tnr  0.971388    1.000000   0\n#> 16                     max fnr  0.971388    0.997093   0\n#> 17                     max fpr  0.000141    1.000000 399\n#> 18                     max tpr  0.003402    1.000000 386\n#> \n#> $gains_lift_table\n#> Gains/Lift Table: Avg response rate: 12,04 %, avg score: 11,81 %\n#>    group cumulative_data_fraction lower_threshold     lift cumulative_lift\n#> 1      1               0.01014696        0.919240 7.735164        7.735164\n#> 2      2               0.02029391        0.875515 7.735164        7.735164\n#> 3      3               0.03009097        0.836876 6.824543        7.438683\n#> 4      4               0.04023793        0.807090 6.016239        7.079980\n#> 5      5               0.05003499        0.770524 6.527824        6.971865\n#> 6      6               0.10006998        0.510412 5.286998        6.129432\n#> 7      7               0.15010497        0.261862 3.195438        5.151434\n#> 8      8               0.20013996        0.121874 2.033461        4.371941\n#> 9      9               0.30020994        0.045614 0.668137        3.137339\n#> 10    10               0.39993002        0.022208 0.378968        2.449556\n#> 11    11               0.50000000        0.011998 0.174297        1.994186\n#> 12    12               0.60006998        0.006925 0.000000        1.661628\n#> 13    13               0.69979006        0.004539 0.000000        1.424846\n#> 14    14               0.79986004        0.002658 0.029049        1.250219\n#> 15    15               0.89993002        0.001358 0.000000        1.111198\n#> 16    16               1.00000000        0.000003 0.000000        1.000000\n#>    response_rate    score cumulative_response_rate cumulative_score\n#> 1       0.931034 0.939646                 0.931034         0.939646\n#> 2       0.931034 0.898872                 0.931034         0.919259\n#> 3       0.821429 0.859332                 0.895349         0.899748\n#> 4       0.724138 0.820790                 0.852174         0.879837\n#> 5       0.785714 0.788200                 0.839161         0.861894\n#> 6       0.636364 0.649414                 0.737762         0.755654\n#> 7       0.384615 0.373258                 0.620047         0.628189\n#> 8       0.244755 0.187099                 0.526224         0.517916\n#> 9       0.080420 0.075108                 0.377622         0.370314\n#> 10      0.045614 0.032250                 0.294838         0.286020\n#> 11      0.020979 0.016163                 0.240028         0.232011\n#> 12      0.000000 0.009148                 0.200000         0.194845\n#> 13      0.000000 0.005644                 0.171500         0.167884\n#> 14      0.003497 0.003554                 0.150481         0.147325\n#> 15      0.000000 0.002018                 0.133748         0.131167\n#> 16      0.000000 0.000729                 0.120364         0.118114\n#>    capture_rate cumulative_capture_rate        gain cumulative_gain\n#> 1      0.078488                0.078488  673.516439      673.516439\n#> 2      0.078488                0.156977  673.516439      673.516439\n#> 3      0.066860                0.223837  582.454319      643.868307\n#> 4      0.061047                0.284884  501.623897      607.997978\n#> 5      0.063953                0.348837  552.782392      597.186534\n#> 6      0.264535                0.613372  428.699789      512.943161\n#> 7      0.159884                0.773256  219.543828      415.143384\n#> 8      0.101744                0.875000  103.346073      337.194056\n#> 9      0.066860                0.941860  -33.186290      213.733940\n#> 10     0.037791                0.979651  -62.103223      144.955645\n#> 11     0.017442                0.997093  -82.570337       99.418605\n#> 12     0.000000                0.997093 -100.000000       66.162791\n#> 13     0.000000                0.997093 -100.000000       42.484593\n#> 14     0.002907                1.000000  -97.095056       25.021872\n#> 15     0.000000                1.000000 -100.000000       11.119751\n#> 16     0.000000                1.000000 -100.000000        0.000000\n#>    kolmogorov_smirnov\n#> 1            0.077693\n#> 2            0.155386\n#> 3            0.220257\n#> 4            0.278122\n#> 5            0.339688\n#> 6            0.583539\n#> 7            0.708419\n#> 8            0.767204\n#> 9            0.729450\n#> 10           0.659047\n#> 11           0.565112\n#> 12           0.451349\n#> 13           0.337984\n#> 14           0.227526\n#> 15           0.113763\n#> 16           0.000000\n#> \n#> $residual_deviance\n#> [1] 1003.751\n#> \n#> $null_deviance\n#> [1] 2101.565\n#> \n#> $AIC\n#> [1] 1015.751\n#> \n#> $null_degrees_of_freedom\n#> [1] 2857\n#> \n#> $residual_degrees_of_freedom\n#> [1] 2852"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#classifier-summary-metrics-1",
    "href": "content/01_journal/Challenge5/Challenge5.html#classifier-summary-metrics-1",
    "title": "Challenge5",
    "section": "\n10.13 Classifier Summary Metrics",
    "text": "10.13 Classifier Summary Metrics\n\nh2o.auc(performance_h2o, train = T, valid = T, xval = T)\n\n#> [1] 0.9497442\n\n## [1] 0.8588763\n\n# Caution: \"train, \"val\", and \"xval\" arugments only work for models (not performance objects)\nh2o.auc(stacked_ensemble_h2o, train = T, valid = T, xval = T)\n\n#>     train     valid      xval \n#> 0.9898558 0.9532463 0.9534082\n\n##     train     valid      xval \n## 0.9892475 0.8219522 0.8383290 \n\nh2o.giniCoef(performance_h2o)\n\n#> [1] 0.8994884\n\n## [1] 0.7177527\nh2o.logloss(performance_h2o)\n\n#> [1] 0.1756038\n\n## [1] 0.2941769\n\n# result for the training data\nh2o.confusionMatrix(stacked_ensemble_h2o)\n\n\n\n  \n\n\n## Confusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.358554294328892:\n##         No Yes    Error      Rate\n## No     871  20 0.022447   =20/891\n## Yes     23 151 0.132184   =23/174\n## Totals 894 171 0.040376  =43/1065\n\n# result for the hold out set\nh2o.confusionMatrix(performance_h2o)\n\n\n\n  \n\n\n## Confusion Matrix (vertical: actual; across: predicted)  for max f1 @ threshold = 0.498049256506051:\n##         No Yes    Error     Rate\n## No     179   9 0.047872   =9/188\n## Yes     14  18 0.437500   =14/32\n## Totals 193  27 0.104545  =23/220\n\n\nperformance_tbl <- performance_h2o %>%\n    h2o.metric() %>%\n    as.tibble() \n\nperformance_tbl %>% \n  glimpse()\n\n#> Rows: 400\n#> Columns: 20\n#> $ threshold               <dbl> 0.9713882, 0.9659111, 0.9614607, 0.9506280, 0.…\n#> $ f1                      <dbl> 0.005797101, 0.011560694, 0.022988506, 0.03428…\n#> $ f2                      <dbl> 0.003631082, 0.007256894, 0.014492754, 0.02170…\n#> $ f0point5                <dbl> 0.01436782, 0.02840909, 0.05555556, 0.08152174…\n#> $ accuracy                <dbl> 0.8799860, 0.8803359, 0.8810357, 0.8817355, 0.…\n#> $ precision               <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ recall                  <dbl> 0.002906977, 0.005813953, 0.011627907, 0.01744…\n#> $ specificity             <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ absolute_mcc            <dbl> 0.05057644, 0.07153841, 0.10120604, 0.12399503…\n#> $ min_per_class_accuracy  <dbl> 0.002906977, 0.005813953, 0.011627907, 0.01744…\n#> $ mean_per_class_accuracy <dbl> 0.5014535, 0.5029070, 0.5058140, 0.5087209, 0.…\n#> $ tns                     <dbl> 2514, 2514, 2514, 2514, 2514, 2514, 2513, 2513…\n#> $ fns                     <dbl> 343, 342, 340, 338, 336, 335, 334, 332, 330, 3…\n#> $ fps                     <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2…\n#> $ tps                     <dbl> 1, 2, 4, 6, 8, 9, 10, 12, 14, 16, 19, 22, 24, …\n#> $ tnr                     <dbl> 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.…\n#> $ fnr                     <dbl> 0.9970930, 0.9941860, 0.9883721, 0.9825581, 0.…\n#> $ fpr                     <dbl> 0.0000000000, 0.0000000000, 0.0000000000, 0.00…\n#> $ tpr                     <dbl> 0.002906977, 0.005813953, 0.011627907, 0.01744…\n#> $ idx                     <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …\n\n\n\ntheme_new <- theme(\n      legend.position  = \"bottom\",\n      legend.key       = element_blank(),,\n      panel.background = element_rect(fill   = \"transparent\"),\n      panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n      panel.grid.major = element_line(color = \"grey\", size = 0.333)\n      ) \n\n\nperformance_tbl %>%\n    filter(f1 == max(f1))\n\n\n\n  \n\n\nperformance_tbl %>%\n    ggplot(aes(x = threshold)) +\n    geom_line(aes(y = precision), color = \"blue\", size = 1) +\n    geom_line(aes(y = recall), color = \"red\", size = 1) +\n    \n    # Insert line where precision and recall are harmonically optimized\n    geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n    labs(title = \"Precision vs Recall\", y = \"value\") +\n    theme_new"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#precision-vs-recall-plot-1",
    "href": "content/01_journal/Challenge5/Challenge5.html#precision-vs-recall-plot-1",
    "title": "Challenge5",
    "section": "\n11.1 5 Precision vs Recall Plot",
    "text": "11.1 5 Precision vs Recall Plot\n\n# Precision vs Recall\n\nload_model_performance_metrics <- function(path, test_tbl) {\n    \n    model_h2o <- h2o.loadModel(path)\n    perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n    \n    perf_h2o %>%\n        h2o.metric() %>%\n        as_tibble() %>%\n        mutate(auc = h2o.auc(perf_h2o)) %>%\n        select(tpr, fpr, auc, precision, recall)\n    \n}\n\nmodel_metrics_tbl <- fs::dir_info(path = \"05_Modeling/h20_models/\") %>%\n    select(path) %>%\n    mutate(metrics = map(path, load_model_performance_metrics, test_tbl)) %>%\n    unnest(cols = metrics)\n\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nmodel_metrics_tbl %>%\n    mutate(\n        path = str_split(path, pattern = \"/\", simplify = T)[,3] %>% as_factor(),\n        auc  = auc %>% round(3) %>% as.character() %>% as_factor()\n    ) %>%\n    ggplot(aes(recall, precision, color = path, linetype = auc)) +\n    geom_line(size = 1) +\n    theme_new + \n    theme(\n      legend.direction = \"vertical\",\n      ) +\n    labs(\n        title = \"Precision vs Recall Plot\",\n        subtitle = \"Performance of 3 Top Performing Models\"\n    )"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#gain-plot",
    "href": "content/01_journal/Challenge5/Challenge5.html#gain-plot",
    "title": "Challenge5",
    "section": "\n11.2 6 Gain Plot",
    "text": "11.2 6 Gain Plot\n\n# Gain & Lift\n\nranked_predictions_tbl <- predictions_tbl %>%\n    bind_cols(test_tbl) %>%\n    select(predict:Yes, went_on_backorder) %>%\n    # Sorting from highest to lowest class probability\n    arrange(desc(Yes))\n\n\nranked_predictions_tbl %>%\n    mutate(ntile = ntile(Yes, n = 10)) %>%\n    group_by(ntile) %>%\n    summarise(\n        cases = n(),\n        responses = sum(went_on_backorder == \"Yes\")\n    ) %>%\n    arrange(desc(ntile))\n\n\n\n  \n\n\n\n\ncalculated_gain_lift_tbl <- ranked_predictions_tbl %>%\n    mutate(ntile = ntile(Yes, n = 10)) %>%\n    group_by(ntile) %>%\n    summarise(\n        cases = n(),\n        responses = sum(went_on_backorder == \"Yes\")\n    ) %>%\n    arrange(desc(ntile)) %>%\n    \n    # Add group numbers (opposite of ntile)\n    mutate(group = row_number()) %>%\n    select(group, cases, responses) %>%\n    \n    # Calculations\n    mutate(\n        cumulative_responses = cumsum(responses),\n        pct_responses        = responses / sum(responses),\n        gain                 = cumsum(pct_responses),\n        cumulative_pct_cases = cumsum(cases) / sum(cases),\n        lift                 = gain / cumulative_pct_cases,\n        gain_baseline        = cumulative_pct_cases,\n        lift_baseline        = gain_baseline / cumulative_pct_cases\n    )\n\ncalculated_gain_lift_tbl \n\n\n\n  \n\n\n\n\ngain_lift_tbl <- performance_h2o %>%\n    h2o.gainsLift() %>%\n    as.tibble()\n\n## Gain Chart\n\ngain_transformed_tbl <- gain_lift_tbl %>% \n    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n    select(-contains(\"lift\")) %>%\n    mutate(baseline = cumulative_data_fraction) %>%\n    rename(gain     = cumulative_capture_rate) %>%\n    # prepare the data for the plotting (for the color and group aesthetics)\n    pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\ngain_transformed_tbl %>%\n    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n    geom_line(size = 1.5) +\n    labs(\n        title = \"Gain Chart\",\n        x = \"Cumulative Data Fraction\",\n        y = \"Gain\"\n    ) +\n    theme_new"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#lift-plot",
    "href": "content/01_journal/Challenge5/Challenge5.html#lift-plot",
    "title": "Challenge5",
    "section": "\n11.3 7. Lift Plot",
    "text": "11.3 7. Lift Plot\n\n## Lift Plot\n\nlift_transformed_tbl <- gain_lift_tbl %>% \n    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n    select(-contains(\"capture\")) %>%\n    mutate(baseline = 1) %>%\n    rename(lift = cumulative_lift) %>%\n    pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n\nlift_transformed_tbl %>%\n    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n    geom_line(size = 1.5) +\n    labs(\n        title = \"Lift Chart\",\n        x = \"Cumulative Data Fraction\",\n        y = \"Lift\"\n    ) +\n    theme_new"
  },
  {
    "objectID": "content/01_journal/Challenge5/Challenge5.html#dashboard-with-cowplot",
    "href": "content/01_journal/Challenge5/Challenge5.html#dashboard-with-cowplot",
    "title": "Challenge5",
    "section": "\n11.4 8. Dashboard with cowplot",
    "text": "11.4 8. Dashboard with cowplot\n\n# 5. Performance Visualization ----  \nlibrary(cowplot)\nlibrary(glue)\n\n\n# set values to test the function while building it\nh2o_leaderboard <- automl_models_h2o@leaderboard\nnewdata <- test_tbl\norder_by <- \"auc\"\nmax_models <- 4\nsize <- 1\n\nplot_h2o_performance <- function(h2o_leaderboard, newdata, order_by = c(\"auc\", \"logloss\"),\n                                 max_models = 3, size = 1.5) {\n    \n    # Inputs\n    \n    leaderboard_tbl <- h2o_leaderboard %>%\n        as_tibble() %>%\n        slice(1:max_models)\n    \n    newdata_tbl <- newdata %>%\n        as_tibble()\n    \n    # Selecting the first, if nothing is provided\n    order_by      <- tolower(order_by[[1]]) \n    \n    # Convert string stored in a variable to column name (symbol)\n    order_by_expr <- rlang::sym(order_by)\n\n    # Turn of the progress bars ( opposite h2o.show_progress())\n    h2o.no_progress()\n    \n    # 1. Model metrics\n    \n    get_model_performance_metrics <- function(model_id, test_tbl) {\n        \n        model_h2o <- h2o.getModel(model_id)\n        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl))\n        \n        perf_h2o %>%\n            h2o.metric() %>%\n            as.tibble() %>%\n            select(threshold, tpr, fpr, precision, recall)\n        \n    }\n    \n    model_metrics_tbl <- leaderboard_tbl %>%\n        mutate(metrics = map(model_id, get_model_performance_metrics, newdata_tbl)) %>%\n        unnest(cols = metrics) %>%\n        mutate(\n          model_id = as_factor(model_id) %>% \n                      # programmatically reorder factors depending on order_by\n                      fct_reorder(!! order_by_expr, \n                                  .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n          auc      = auc %>% \n                      round(3) %>% \n                      as.character() %>% \n                      as_factor() %>% \n                      fct_reorder(as.numeric(model_id)),\n          logloss  = logloss %>% \n                      round(4) %>% \n                      as.character() %>% \n                      as_factor() %>% \n                      fct_reorder(as.numeric(model_id))\n        )\n    \n    \n    # 1A. ROC Plot\n    \n    p1 <- model_metrics_tbl %>%\n        ggplot(aes(fpr, tpr, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        theme_new +\n        labs(title = \"ROC\", x = \"FPR\", y = \"TPR\") +\n        theme(legend.direction = \"vertical\") \n        \n    \n    # 1B. Precision vs Recall\n    \n    p2 <- model_metrics_tbl %>%\n        ggplot(aes(recall, precision, color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        theme_new +\n        labs(title = \"Precision Vs Recall\", x = \"Recall\", y = \"Precision\") +\n        theme(legend.position = \"none\") \n    \n    \n    # 2. Gain / Lift\n    \n    get_gain_lift <- function(model_id, test_tbl) {\n        \n        model_h2o <- h2o.getModel(model_id)\n        perf_h2o  <- h2o.performance(model_h2o, newdata = as.h2o(test_tbl)) \n        \n        perf_h2o %>%\n            h2o.gainsLift() %>%\n            as.tibble() %>%\n            select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift)\n        \n    }\n    \n    gain_lift_tbl <- leaderboard_tbl %>%\n        mutate(metrics = map(model_id, get_gain_lift, newdata_tbl)) %>%\n        unnest(cols = metrics) %>%\n        mutate(\n            model_id = as_factor(model_id) %>% \n                fct_reorder(!! order_by_expr, \n                            .desc = ifelse(order_by == \"auc\", TRUE, FALSE)),\n            auc  = auc %>% \n                round(3) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id)),\n            logloss = logloss %>% \n                round(4) %>% \n                as.character() %>% \n                as_factor() %>% \n                fct_reorder(as.numeric(model_id))\n        ) %>%\n        rename(\n            gain = cumulative_capture_rate,\n            lift = cumulative_lift\n        ) \n    \n    # 2A. Gain Plot\n    \n    p3 <- gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, gain, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size,) +\n        geom_segment(x = 0, y = 0, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        theme_new +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Gain\",\n             x = \"Cumulative Data Fraction\", y = \"Gain\") +\n        theme(legend.position = \"none\")\n    \n    # 2B. Lift Plot\n    \n    p4 <- gain_lift_tbl %>%\n        ggplot(aes(cumulative_data_fraction, lift, \n                          color = model_id, linetype = !! order_by_expr)) +\n        geom_line(size = size) +\n        geom_segment(x = 0, y = 1, xend = 1, yend = 1, \n                     color = \"red\", size = size, linetype = \"dotted\") +\n        theme_new +\n        expand_limits(x = c(0, 1), y = c(0, 1)) +\n        labs(title = \"Lift\",\n             x = \"Cumulative Data Fraction\", y = \"Lift\") +\n        theme(legend.position = \"none\") \n    \n    \n    # Combine using cowplot\n    \n    # cowplot::get_legend extracts a legend from a ggplot object\n    p_legend <- get_legend(p1)\n    # Remove legend from p1\n    p1 <- p1 + theme(legend.position = \"none\")\n    \n    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n    p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n    \n    # cowplot::ggdraw() sets up a drawing layer\n    p_title <- ggdraw() + \n    \n        # cowplot::draw_label() draws text on a ggdraw layer / ggplot object\n        draw_label(\"H2O Model Metrics\", size = 18, fontface = \"bold\", \n                   color = \"#2C3E50\")\n    \n    p_subtitle <- ggdraw() + \n        draw_label(glue(\"Ordered by {toupper(order_by)}\"), size = 10,  \n                   color = \"#2C3E50\")\n    \n    # Combine everything\n    ret <- plot_grid(p_title, p_subtitle, p, p_legend, \n    \n                     # Adjust the relative spacing, so that the legends always fits\n                     ncol = 1, rel_heights = c(0.05, 0.05, 1, 0.05 * max_models))\n    \n    h2o.show_progress()\n    \n    return(ret)\n    \n}\n\nautoml_models_h2o@leaderboard %>%\n    plot_h2o_performance(newdata = test_tbl, order_by = \"logloss\", \n                         size = 0.5, max_models = 4)"
  },
  {
    "objectID": "content/01_journal/Challenge6/Challenge6.html",
    "href": "content/01_journal/Challenge6/Challenge6.html",
    "title": "Challenge6",
    "section": "",
    "text": "This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\n\n# LIME FEATURE EXPLANATION ----\n\n# 1. Setup ----\n\n# Load Libraries \n\nlibrary(h2o)\n\n#> \n#> ----------------------------------------------------------------------\n#> \n#> Your next step is to start H2O:\n#>     > h2o.init()\n#> \n#> For H2O package documentation, ask for help:\n#>     > ??h2o\n#> \n#> After starting H2O, you can use the Web UI at http://localhost:54321\n#> For more information visit https://docs.h2o.ai\n#> \n#> ----------------------------------------------------------------------\n\n\n#> \n#> Attache Paket: 'h2o'\n\n\n#> Die folgenden Objekte sind maskiert von 'package:stats':\n#> \n#>     cor, sd, var\n\n\n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n#>     colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n#>     log10, log1p, log2, round, signif, trunc\n\nlibrary(recipes)\n\n#> Lade nötiges Paket: dplyr\n\n\n#> \n#> Attache Paket: 'dplyr'\n\n\n#> Die folgenden Objekte sind maskiert von 'package:stats':\n#> \n#>     filter, lag\n\n\n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     intersect, setdiff, setequal, union\n\n\n#> \n#> Attache Paket: 'recipes'\n\n\n#> Das folgende Objekt ist maskiert 'package:stats':\n#> \n#>     step\n\nlibrary(readxl)\nlibrary(tidyverse)\n\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ forcats   1.0.0     ✔ readr     2.1.4\n#> ✔ ggplot2   3.4.2     ✔ stringr   1.5.0\n#> ✔ lubridate 1.9.2     ✔ tibble    3.2.1\n#> ✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ lubridate::day()   masks h2o::day()\n#> ✖ dplyr::filter()    masks stats::filter()\n#> ✖ stringr::fixed()   masks recipes::fixed()\n#> ✖ lubridate::hour()  masks h2o::hour()\n#> ✖ dplyr::lag()       masks stats::lag()\n#> ✖ lubridate::month() masks h2o::month()\n#> ✖ lubridate::week()  masks h2o::week()\n#> ✖ lubridate::year()  masks h2o::year()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\n#> Lade nötiges Paket: PerformanceAnalytics\n#> Lade nötiges Paket: xts\n#> Lade nötiges Paket: zoo\n#> \n#> Attache Paket: 'zoo'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> \n#> ######################### Warning from 'xts' package ##########################\n#> #                                                                             #\n#> # The dplyr lag() function breaks how base R's lag() function is supposed to  #\n#> # work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n#> # source() into this session won't work correctly.                            #\n#> #                                                                             #\n#> # Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n#> # conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n#> # dplyr from breaking base R's lag() function.                                #\n#> #                                                                             #\n#> # Code in packages is not affected. It's protected by R's namespace mechanism #\n#> # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#> #                                                                             #\n#> ###############################################################################\n#> \n#> Attache Paket: 'xts'\n#> \n#> Die folgenden Objekte sind maskiert von 'package:dplyr':\n#> \n#>     first, last\n#> \n#> \n#> Attache Paket: 'PerformanceAnalytics'\n#> \n#> Das folgende Objekt ist maskiert 'package:graphics':\n#> \n#>     legend\n#> \n#> Lade nötiges Paket: quantmod\n#> Lade nötiges Paket: TTR\n#> Registered S3 method overwritten by 'quantmod':\n#>   method            from\n#>   as.zoo.data.frame zoo\n\nlibrary(lime)\n\n#> \n#> Attache Paket: 'lime'\n#> \n#> Das folgende Objekt ist maskiert 'package:dplyr':\n#> \n#>     explain\n\nlibrary(rsample)\nlibrary(ggplot2)\n\n# Load Data\nemployee_attrition_tbl <- read_csv(\"datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n\n#> Rows: 1470 Columns: 35\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\n#> dbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndefinitions_raw_tbl    <- read_excel(\"data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n\n#> New names:\n#> • `` -> `...1`\n#> • `` -> `...2`\n\n# Processing Pipeline\nsource(\"process_hr_data_readable.R\")\n\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n\n#> Joining with `by = join_by(Education)`\n#> Joining with `by = join_by(EnvironmentSatisfaction)`\n#> Joining with `by = join_by(JobInvolvement)`\n#> Joining with `by = join_by(JobSatisfaction)`\n#> Joining with `by = join_by(PerformanceRating)`\n#> Joining with `by = join_by(RelationshipSatisfaction)`\n#> Joining with `by = join_by(WorkLifeBalance)`\n\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%\n                step_zv(all_predictors()) %>%\n                step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %>% \n                prep()\n\nrecipe_obj\n\n#> \n#> ── Recipe ──────────────────────────────────────────────────────────────────────\n#> \n#> ── Inputs \n#> Number of variables by role\n#> outcome:    1\n#> predictor: 34\n#> \n#> ── Training information \n#> Training data contained 1249 data points and no incomplete rows.\n#> \n#> ── Operations \n#> • Zero variance filter removed: EmployeeCount, Over18, StandardHours | Trained\n#> • Variable mutation for: JobLevel, StockOptionLevel | Trained\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# 2. Models ----\n\nh2o.init()\n\n#>  Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         1 hours 47 minutes \n#>     H2O cluster timezone:       Europe/Berlin \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.40.0.1 \n#>     H2O cluster version age:    3 months and 21 days \n#>     H2O cluster name:           H2O_started_from_R_tiend_ham688 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   2.94 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.2.3 (2023-03-15 ucrt)\n\n\n#> Warning in h2o.clusterInfo(): \n#> Your H2O cluster version is (3 months and 21 days) old. There may be a newer version available.\n#> Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n\nautoml_leader <- h2o.loadModel(\"StackedEnsemble_BestOfFamily_3_AutoML_2_20230525_211824\")\nautoml_leader\n\n#> Model Details:\n#> ==============\n#> \n#> H2OBinomialModel: stackedensemble\n#> Model ID:  StackedEnsemble_BestOfFamily_3_AutoML_2_20230525_211824 \n#> Model Summary for Stacked Ensemble: \n#>                                          key            value\n#> 1                          Stacking strategy cross_validation\n#> 2       Number of base models (used / total)              3/5\n#> 3           # GBM base models (used / total)              1/1\n#> 4           # GLM base models (used / total)              1/1\n#> 5  # DeepLearning base models (used / total)              1/1\n#> 6           # DRF base models (used / total)              0/2\n#> 7                      Metalearner algorithm              GLM\n#> 8         Metalearner fold assignment scheme           Random\n#> 9                         Metalearner nfolds                5\n#> 10                   Metalearner fold_column               NA\n#> 11        Custom metalearner hyperparameters             None\n#> \n#> \n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on training data. **\n#> \n#> MSE:  0.06548413\n#> RMSE:  0.2558987\n#> LogLoss:  0.2304629\n#> Mean Per-Class Error:  0.1707158\n#> AUC:  0.9220945\n#> AUCPR:  0.8093744\n#> Gini:  0.8441889\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>         No Yes    Error      Rate\n#> No     886  23 0.025303   =23/909\n#> Yes     49 106 0.316129   =49/155\n#> Totals 935 129 0.067669  =72/1064\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold      value idx\n#> 1                       max f1  0.319522   0.746479 109\n#> 2                       max f2  0.153294   0.765247 190\n#> 3                 max f0point5  0.418566   0.801105  82\n#> 4                 max accuracy  0.319522   0.932331 109\n#> 5                max precision  0.954868   1.000000   0\n#> 6                   max recall  0.007825   1.000000 384\n#> 7              max specificity  0.954868   1.000000   0\n#> 8             max absolute_mcc  0.319522   0.711784 109\n#> 9   max min_per_class_accuracy  0.148133   0.864516 194\n#> 10 max mean_per_class_accuracy  0.153294   0.865226 190\n#> 11                     max tns  0.954868 909.000000   0\n#> 12                     max fns  0.954868 154.000000   0\n#> 13                     max fps  0.000832 909.000000 399\n#> 14                     max tps  0.007825 155.000000 384\n#> 15                     max tnr  0.954868   1.000000   0\n#> 16                     max fnr  0.954868   0.993548   0\n#> 17                     max fpr  0.000832   1.000000 399\n#> 18                     max tpr  0.007825   1.000000 384\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on validation data. **\n#> \n#> MSE:  0.1044121\n#> RMSE:  0.3231286\n#> LogLoss:  0.340833\n#> Mean Per-Class Error:  0.1889545\n#> AUC:  0.8728965\n#> AUCPR:  0.7327814\n#> Gini:  0.7457931\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>         No Yes    Error     Rate\n#> No     134  13 0.088435  =13/147\n#> Yes     11  27 0.289474   =11/38\n#> Totals 145  40 0.129730  =24/185\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold      value idx\n#> 1                       max f1  0.257768   0.692308  39\n#> 2                       max f2  0.221863   0.725000  47\n#> 3                 max f0point5  0.375262   0.719178  26\n#> 4                 max accuracy  0.375262   0.875676  26\n#> 5                max precision  0.909310   1.000000   0\n#> 6                   max recall  0.018888   1.000000 139\n#> 7              max specificity  0.909310   1.000000   0\n#> 8             max absolute_mcc  0.257768   0.610507  39\n#> 9   max min_per_class_accuracy  0.156669   0.789116  60\n#> 10 max mean_per_class_accuracy  0.221863   0.816953  47\n#> 11                     max tns  0.909310 147.000000   0\n#> 12                     max fns  0.909310  37.000000   0\n#> 13                     max fps  0.000908 147.000000 184\n#> 14                     max tps  0.018888  38.000000 139\n#> 15                     max tnr  0.909310   1.000000   0\n#> 16                     max fnr  0.909310   0.973684   0\n#> 17                     max fpr  0.000908   1.000000 184\n#> 18                     max tpr  0.018888   1.000000 139\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> H2OBinomialMetrics: stackedensemble\n#> ** Reported on cross-validation data. **\n#> ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n#> \n#> MSE:  0.08582408\n#> RMSE:  0.2929575\n#> LogLoss:  0.3007471\n#> Mean Per-Class Error:  0.2284254\n#> AUC:  0.8401789\n#> AUCPR:  0.6047858\n#> Gini:  0.6803577\n#> \n#> Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n#>         No Yes    Error       Rate\n#> No     828  81 0.089109    =81/909\n#> Yes     57  98 0.367742    =57/155\n#> Totals 885 179 0.129699  =138/1064\n#> \n#> Maximum Metrics: Maximum metrics at their respective thresholds\n#>                         metric threshold      value idx\n#> 1                       max f1  0.273443   0.586826 140\n#> 2                       max f2  0.207638   0.644599 176\n#> 3                 max f0point5  0.481961   0.636550  71\n#> 4                 max accuracy  0.481961   0.892857  71\n#> 5                max precision  0.961951   1.000000   0\n#> 6                   max recall  0.002828   1.000000 397\n#> 7              max specificity  0.961951   1.000000   0\n#> 8             max absolute_mcc  0.390134   0.516054  93\n#> 9   max min_per_class_accuracy  0.160560   0.774194 213\n#> 10 max mean_per_class_accuracy  0.207638   0.786557 176\n#> 11                     max tns  0.961951 909.000000   0\n#> 12                     max fns  0.961951 154.000000   0\n#> 13                     max fps  0.001325 909.000000 399\n#> 14                     max tps  0.002828 155.000000 397\n#> 15                     max tnr  0.961951   1.000000   0\n#> 16                     max fnr  0.961951   0.993548   0\n#> 17                     max fpr  0.001325   1.000000 399\n#> 18                     max tpr  0.002828   1.000000 397\n#> \n#> Gains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\n#> Cross-Validation Metrics Summary: \n#>                mean       sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\n#> accuracy   0.903100 0.019689   0.879167   0.932773   0.894472   0.901478\n#> auc        0.851520 0.024984   0.821533   0.880376   0.873540   0.835510\n#> err        0.096900 0.019689   0.120833   0.067227   0.105528   0.098522\n#> err_count 20.600000 5.128353  29.000000  16.000000  21.000000  20.000000\n#> f0point5   0.676573 0.038446   0.628571   0.698925   0.722543   0.646552\n#>           cv_5_valid\n#> accuracy    0.907609\n#> auc         0.846641\n#> err         0.092391\n#> err_count  17.000000\n#> f0point5    0.686275\n#> \n#> ---\n#>                         mean        sd cv_1_valid cv_2_valid cv_3_valid\n#> precision           0.713144  0.047590   0.647059   0.764706   0.735294\n#> r2                  0.309256  0.021469   0.297469   0.317660   0.338736\n#> recall              0.566791  0.062890   0.564103   0.520000   0.675676\n#> residual_deviance 127.260010 20.341250 160.076320 112.791030 132.083560\n#> rmse                0.292059  0.024484   0.309209   0.253270   0.316368\n#> specificity         0.958864  0.016910   0.940299   0.981221   0.944444\n#>                   cv_4_valid cv_5_valid\n#> precision           0.681818   0.736842\n#> r2                  0.281639   0.310776\n#> recall              0.535714   0.538462\n#> residual_deviance 121.883100 109.466020\n#> rmse                0.292263   0.289186\n#> specificity         0.960000   0.968354"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  }
]